{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADED EXERCISE - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second graded exercise. In this exercise, we will consider a LASSO regression problem. \n",
    "\n",
    "You are asked to fill in the code in a couple of cells throughout the exercise. For each such cell we provided tests which are run along with the cell and save your results to a file. You will receive points for each individual cell. The tests immediately show you whether your code is correct.\n",
    "\n",
    "Please note that there are also a couple of theoretical True/False questions in the end of this file!\n",
    "\n",
    "**Before you finish, please make sure to upload 2 files to Moodle:**\n",
    "* **graded_exercise_2.ipynb**\n",
    "* **answers_<SCIPER>.npz (e.g. \"answers_280595.npz\")**\n",
    "    \n",
    "Good luck! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lib import helpers, tests\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your sciper number here\n",
    "sciper_number = 274999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "First we load the training data, provided in the file 'train_data.npy'. Please ensure that you downloaded the required file on Moodle and then placed it in the same directory as this notebook. Notice that only the training data is provided and the testing data is not given, as in a typical real-world scenario. The hold-out testing data will be used to assess the correctness of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data feature shape: (500, 1)\n",
      "Number of train examples: 500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = np.load('train_data.npy')\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "print('Training data feature shape: {}'.format(X_train.shape))\n",
    "print('Number of train examples: {}'.format(X_train.shape[0]))\n",
    "\n",
    "plt.plot(X_train, y_train, linestyle='', marker='x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Normalize\n",
    "\n",
    "Please complete the function \"normalize\", that standardizes the features of a given data set $X$ so that each feature dimension has zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_normalization] Testing normalization on random data (N=100, d=3)...\n",
      "[test_normalization] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def find_stats(X):\n",
    "    \"\"\" Computes the mean and std of X.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Data, shape (N, D), N is # points, D is dimension.\n",
    "        \n",
    "    Returns:\n",
    "        mu (np.array): Mean, shape (D, ).\n",
    "        std (np.array): Std, shape (D, ).\n",
    "    \"\"\"\n",
    "    \n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "\n",
    "    mu = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return mu, std\n",
    "\n",
    "    #######################################\n",
    "\n",
    "def normalize(X, mu, std):\n",
    "    \"\"\" Transforms the data so that they have mean 0 and std 1.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Data, shape (N, D), N is # points, D is dimension.\n",
    "        mu (np.array): Mean, shape (D, ).\n",
    "        std (np.array): Std, shape (D, ).\n",
    "    \"\"\"\n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "\n",
    "    X = (X - mu) / std\n",
    "    return X\n",
    "\n",
    "    #######################################\n",
    "    \n",
    "tests.test_normalization(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Expansion\n",
    "\n",
    "Please complete the function \"expand\", that performs a polynomial feature expansion of a given data set $X$ up to degree $\\text{deg}$. You may use functions provided by the package scikit-learn for this purpose, namely `PolynomialFeatures`. Hint: You can access the documentation by typing the function/class name followed by a question mark '?'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_feature_expansion] Testing degree 7 polynomial feature expansion on random data (N=100, d=3)...\n",
      "[test_feature_expansion] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def expand(X, degree):\n",
    "    \"\"\" Expands the features.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Data, shape (N, Din), N is # points, Din is dimension.\n",
    "        \n",
    "    returns:\n",
    "        X (np.array): Expanded data, shape (N, Dout).\n",
    "    \"\"\"\n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    result = poly.fit_transform(X)\n",
    "        \n",
    "    return result\n",
    "\n",
    "    #######################################\n",
    "    \n",
    "tests.test_feature_expansion(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lasso Regression\n",
    "\n",
    "Next we will specify our model. In this graded exercise we will use a sparse regression model, i.e. a regression model that only has a few parameters of non-zero values. Sparseness can be encouraged by including a LASSO term (least absolute shrinkage and selection operator) in the loss function, resulting e.g. in:\n",
    "\\begin{align}\n",
    "L(X,\\mathbf{w}) = \\frac{1}{2N}  \\|\\mathbf{y} - \\mathbf{Xw} \\|^2 + \\lambda \\sum_{i} \\left | \\mathbf{w_{i}} \\right| \n",
    "\\end{align}\n",
    "where $\\mathbf{y}$ is $N\\times1$ ; $\\mathbf{X}$ is $N\\times D$ and $\\mathbf{w}$ is $D\\times 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loss\n",
    "\n",
    "Please complete the function \"loss\", that computes the lasso loss defined above, given a data set $\\mathbf{X}$, target values $\\mathbf{y}$, weights $\\mathbf{w}$ and a regularization coefficient $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss_function] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def loss(X,y,w,lmbda):\n",
    "    \"\"\" Computes the loss function. \n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Data, shape (N, D), N is # points, D is dimension.\n",
    "        y (np.array): Labels, shape (N, ).\n",
    "        w (np.array): Weights, shape (D, ).\n",
    "        lmbda (float): Regularization coefficient.\n",
    "    \n",
    "    Returns:\n",
    "        float: Scalar loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "    \n",
    "    term = y - X @ w\n",
    "    \n",
    "    l = 1 / (2 * X.shape[0]) * np.dot(term, term) + lmbda * np.sum(np.abs(w))\n",
    "    return l\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "tests.test_loss_function(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gradient \n",
    "\n",
    "Please complete the function \"gradient\", that computes the gradient of the loss defined above, given a data set $\\mathbf{X}$, target values $\\mathbf{y}$, weights $\\mathbf{w}$ and a regularization coefficient $\\lambda$.\n",
    "\n",
    "Gradient of the loss is following:\n",
    "\\begin{align}\n",
    "\\nabla L(X,\\mathbf{w}) = -\\frac{1}{N}\\mathbf{X^T}(\\mathbf{y}-\\mathbf{Xw}) + \\lambda\\delta(\\mathbf{w})\n",
    "\\end{align}\n",
    "\n",
    "where $\\delta (\\mathbf{w})$ is a vector with entries correspoding\n",
    "\\begin{align}\n",
    "\\delta (\\mathbf{w_i}) =\n",
    " \\begin{cases}\n",
    "  1 & \\text{if } \\mathbf{w_i} > 0 \\\\\n",
    " -1 & \\text{if } \\mathbf{w_i} < 0 \\\\\n",
    "  0 & \\text{if } \\mathbf{w_i} = 0 \n",
    "\\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_gradient] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def gradient(X, y, w, lmbda):\n",
    "    \"\"\" Computes the gradient of lasso loss function w.r.t. \n",
    "    weights `w`.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): Data, shape (N, D), N is # points, D is dimension.\n",
    "        y (np.array): Labels, shape (N, ).\n",
    "        w (np.array): Weights, shape (D, ).\n",
    "        lmbda (float): Regularization coefficient.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Gradient, shape (D, ).\n",
    "    \"\"\"    \n",
    "        \n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "    \n",
    "    w_pos = (w > 0) + 0\n",
    "    w_neg = (w < 0) + 0\n",
    "    \n",
    "    delta = w_pos - w_neg\n",
    "\n",
    "    grad = - 1 / X.shape[0] * X.T @ (y - X @ w) + lmbda * delta\n",
    "    return grad\n",
    "\n",
    "    #######################################    \n",
    "\n",
    "tests.test_gradient(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitting the data\n",
    "\n",
    "Now that we have loaded as well as preprocessed the data and defined our model we can fit our model to the training data.\n",
    "We will train our model via Gradient Descent: We iteratively update the model's weights by computing the gradient (at the current weights) over *all* training examples and then update the weights, for a given number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Training with Gradient Descent\n",
    "\n",
    "Please complete the function \"training_with_gd\", that computes the gradient of the loss defined above, given a data set $X_{train}$, target values $y_{train}$, weights $w$, a number $epochs$ specifying how many times to loop over the entire training data, a learning rate $lr$ and a regularization coefficient $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_gd_training] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def training_with_gd(X_train, y_train, epochs, lr, lmbda, debug_printing_on=True):\n",
    "    \"\"\" Training loop with gradient descent (NOT Stocastic Gradient Descent).\n",
    "    \n",
    "    Args:\n",
    "        X_train (np.array): Training data, shape (N, D).\n",
    "        y_train (np.array): Trianing labels, shape (N, ).\n",
    "        epochs (int): # Epochs.\n",
    "        lr (float): Learning rate.\n",
    "        lmbda (float): Regularization coefficient.\n",
    "        debug_printing_on (bool): Whether to print debug info.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Final weights, shape (D, ).\n",
    "    \"\"\"\n",
    "    \n",
    "    print_every = 100\n",
    "    \n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "    \n",
    "    # initialize the weights with zeros.\n",
    "    w  = np.zeros(X_train.shape[1])\n",
    "    \n",
    "    # iterate a given number of epochs over the training data\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        \n",
    "        #call gradient and update the weights\n",
    "        w -= lr * gradient(X_train, y_train, w, lmbda)\n",
    "\n",
    "        if debug_printing_on and epoch % print_every == 0:\n",
    "            epoch_loss = loss(X_train, y_train, w, lmbda)\n",
    "            print(f\"Epoch {epoch:>4}/{epochs}: {epoch_loss:.7f}\")\n",
    "            \n",
    "    return w\n",
    "\n",
    "    #######################################\n",
    "\n",
    "tests.test_gd_training(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross Validation\n",
    "\n",
    "Let us code cross validation in order to find the optimal $\\lambda$ value and the optimal degree for polynomial feature expansion. For cross validation, we need the error function `error`, a function to split all the indices of the data into k folds `fold_indices`, a function to loop over the folds training and evaluating the model for each fold `run_cross_validation`. Afterwards, in `grid_search_for_hyperparameters`, for each combination of hyperparameters (degree and $\\lambda$ in our case), we use cross validation to find the combination which gives the smallest validation error.\n",
    "\n",
    "Your task is to fill in the missing code in `test_cross_validation` and `grid_search_for_hyperparameters`.\n",
    "\n",
    "To test our LASSO regressor, we will use MSE error on our validation set. MSE error is defined as:\n",
    "\\begin{align}\n",
    "E(\\mathbf{y_{\\text{ground truth}}}, \\mathbf{y_{\\text{prediction}}}) = \\frac{1}{2N}  \\|\\mathbf{y_{\\text{ground truth}}} - \\mathbf{y_{\\text{prediction}}} \\|^2 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(labels, predictions):\n",
    "    \"\"\" MSE error function.\n",
    "    \n",
    "    Args:\n",
    "        labels (np.array): Labels, shape (N, ).\n",
    "        predictions (np.array): Predictions, shape (N, ).\n",
    "\n",
    "    Returns:\n",
    "        float: Scalar error.\n",
    "    \"\"\"\n",
    "    return np.sum((labels - predictions)**2) / labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_indices(num_of_data, num_of_folds):\n",
    "    \"\"\" Shuffles the indices of the data samples and splits them\n",
    "    into `num_of_folds` folds.\n",
    "    \n",
    "    Args:\n",
    "        num_of_data (int): Total number of data samples.\n",
    "        num_of_folds (int): Number of folds.\n",
    "\n",
    "    Returns:\n",
    "        np.array of int: Indices split into folds, shape \n",
    "            (num_of_folds, num_of_data // num_of_folds).\n",
    "    \"\"\"\n",
    "    \n",
    "    split_size = num_of_data // num_of_folds\n",
    "    \n",
    "    k_fold_ind = []\n",
    "    # Generate k_fold set of indices\n",
    "    ind = range(num_of_data)\n",
    "    k_fold_ind = [ind[k * split_size:(k + 1) * split_size] for k in range(num_of_folds)]\n",
    "         \n",
    "    return np.array(k_fold_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(data, labels, k_fold_ind, k):\n",
    "    \"\"\" Splits the `data` and `labels` into train and validation\n",
    "    subsets given the fold indices `k_fold_ind` and the fold \n",
    "    index `k`.\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): Shape (N, D).\n",
    "        labels (np.array): Shape (N, ).\n",
    "        k_fold_ind (np.array): Indices split into folds.\n",
    "        k (int): Fold index.\n",
    "\n",
    "    Returns:\n",
    "        Data and labels split into training and validation subsets.\n",
    "    \"\"\"\n",
    "    # use one split as validation set\n",
    "    val_ind = k_fold_ind[k]\n",
    "    \n",
    "    # use k-1 split to train\n",
    "    train_splits = [i for i in range(k_fold_ind.shape[0]) if i is not k]\n",
    "    train_ind = k_fold_ind[train_splits, :].reshape(-1)\n",
    "   \n",
    "    # Get train and val \n",
    "    training_data = data[train_ind, :]\n",
    "    training_labels = labels[train_ind]\n",
    "    validation_data = data[val_ind, :]\n",
    "    validation_labels = labels[val_ind]\n",
    "    \n",
    "    return training_data, training_labels, validation_data, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000: 0.0631388\n",
      "Epoch  200/1000: 0.0486321\n",
      "Epoch  300/1000: 0.0466677\n",
      "Epoch  400/1000: 0.0463775\n",
      "Epoch  500/1000: 0.0463301\n",
      "Epoch  600/1000: 0.0463138\n",
      "Epoch  700/1000: 0.0463022\n",
      "Epoch  800/1000: 0.0462928\n",
      "Epoch  900/1000: 0.0462856\n",
      "Epoch 1000/1000: 0.0462846\n",
      "Epoch  100/1000: 0.0643369\n",
      "Epoch  200/1000: 0.0500986\n",
      "Epoch  300/1000: 0.0481661\n",
      "Epoch  400/1000: 0.0478973\n",
      "Epoch  500/1000: 0.0478572\n",
      "Epoch  600/1000: 0.0478392\n",
      "Epoch  700/1000: 0.0478304\n",
      "Epoch  800/1000: 0.0478202\n",
      "Epoch  900/1000: 0.0478109\n",
      "Epoch 1000/1000: 0.0478115\n",
      "Epoch  100/1000: 0.0624906\n",
      "Epoch  200/1000: 0.0476513\n",
      "Epoch  300/1000: 0.0456473\n",
      "Epoch  400/1000: 0.0453686\n",
      "Epoch  500/1000: 0.0453276\n",
      "Epoch  600/1000: 0.0453173\n",
      "Epoch  700/1000: 0.0453102\n",
      "Epoch  800/1000: 0.0453086\n",
      "Epoch  900/1000: 0.0453051\n",
      "Epoch 1000/1000: 0.0453002\n",
      "Epoch  100/1000: 0.0628037\n",
      "Epoch  200/1000: 0.0494962\n",
      "Epoch  300/1000: 0.0477099\n",
      "Epoch  400/1000: 0.0474674\n",
      "Epoch  500/1000: 0.0474347\n",
      "Epoch  600/1000: 0.0474302\n",
      "Epoch  700/1000: 0.0474237\n",
      "Epoch  800/1000: 0.0474276\n",
      "Epoch  900/1000: 0.0474299\n",
      "Epoch 1000/1000: 0.0474227\n",
      "Epoch  100/1000: 0.0666385\n",
      "Epoch  200/1000: 0.0501573\n",
      "Epoch  300/1000: 0.0478861\n",
      "Epoch  400/1000: 0.0475371\n",
      "Epoch  500/1000: 0.0474655\n",
      "Epoch  600/1000: 0.0474321\n",
      "Epoch  700/1000: 0.0474096\n",
      "Epoch  800/1000: 0.0473910\n",
      "Epoch  900/1000: 0.0473760\n",
      "Epoch 1000/1000: 0.0473684\n",
      "[test_cross_validation] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def run_cross_validation(k_fold_ind, num_of_folds, data, labels, lmda, degree, epochs=1000, lr=1e-2):\n",
    "    \"\"\" Runs the cross validation. For every fold, splits the data \n",
    "    into training and validation, does feature expansion and normalizes them. \n",
    "    Trains lasso regressor, tests with validation set. Returns overall error.\n",
    "        \n",
    "    Args:\n",
    "        k_fold_ind (np.array): Indices split into folds.\n",
    "        num_of_folds (int): Number of folds.\n",
    "        data (np.array): Shape (N, D).\n",
    "        labels (np.array): Shape (N, ).\n",
    "        lmda (float): The regularization coefficient. \n",
    "        degree (int): The degree of the polynomial feature expansion.\n",
    "        epochs (int): # Epochs.\n",
    "        lr (float): Learning rate.\n",
    "\n",
    "    Returns:\n",
    "        float: The average validation error across all folds.  \n",
    "    \"\"\"\n",
    "    \n",
    "    error_values = np.zeros((num_of_folds, ))\n",
    "    for k in range(num_of_folds):\n",
    "        training_data, training_labels, validation_data, validation_labels = split_train_val(data, labels, k_fold_ind, k)\n",
    "        \n",
    "        #######################################\n",
    "        # Please fill in the required code here\n",
    "        \n",
    "        # Expand training data features and normalize.\n",
    "        training_data = expand(training_data, degree)\n",
    "        \n",
    "        expand_no_bias = training_data[:, 1:]\n",
    "        mu, std = find_stats(expand_no_bias)\n",
    "        expand_no_bias = normalize(expand_no_bias, mu, std)\n",
    "        \n",
    "        training_data[:, 1:] = expand_no_bias\n",
    "        \n",
    "        # Expand validation data and normalize\n",
    "        # Think about which statistics to use for normalization.\n",
    "        validation_data = expand(validation_data, degree)\n",
    "        \n",
    "        expand_no_bias = validation_data[:, 1:]\n",
    "        expand_no_bias = normalize(expand_no_bias, mu, std)\n",
    "        \n",
    "        validation_data[:, 1:] = expand_no_bias\n",
    "\n",
    "        # Train the model, compute the predictions on validation data.\n",
    "        # Store the predictions in variable `prediction`\n",
    "        w = training_with_gd(training_data, training_labels, epochs, lr, lmda)\n",
    "\n",
    "        \n",
    "        prediction = validation_data @ w\n",
    "        #######################################\n",
    "        \n",
    "        # Store the error.\n",
    "        error_values[k] = error(prediction, validation_labels)\n",
    "        \n",
    "    average_error = np.mean(error_values)\n",
    "    \n",
    "    return average_error\n",
    "\n",
    "tests.test_cross_validation(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000: 0.7000605\n",
      "Epoch  200/1000: 0.6687325\n",
      "Epoch  300/1000: 0.6645352\n",
      "Epoch  400/1000: 0.6639729\n",
      "Epoch  500/1000: 0.6638975\n",
      "Epoch  600/1000: 0.6638874\n",
      "Epoch  700/1000: 0.6638861\n",
      "Epoch  800/1000: 0.6638859\n",
      "Epoch  900/1000: 0.6638859\n",
      "Epoch 1000/1000: 0.6638859\n",
      "Epoch  100/1000: 0.7449946\n",
      "Epoch  200/1000: 0.7136188\n",
      "Epoch  300/1000: 0.7094151\n",
      "Epoch  400/1000: 0.7088519\n",
      "Epoch  500/1000: 0.7087764\n",
      "Epoch  600/1000: 0.7087663\n",
      "Epoch  700/1000: 0.7087650\n",
      "Epoch  800/1000: 0.7087648\n",
      "Epoch  900/1000: 0.7087648\n",
      "Epoch 1000/1000: 0.7087648\n",
      "Epoch  100/1000: 0.7252269\n",
      "Epoch  200/1000: 0.6944462\n",
      "Epoch  300/1000: 0.6903223\n",
      "Epoch  400/1000: 0.6897697\n",
      "Epoch  500/1000: 0.6896957\n",
      "Epoch  600/1000: 0.6896858\n",
      "Epoch  700/1000: 0.6896844\n",
      "Epoch  800/1000: 0.6896843\n",
      "Epoch  900/1000: 0.6896842\n",
      "Epoch 1000/1000: 0.6896842\n",
      "Epoch  100/1000: 0.8521165\n",
      "Epoch  200/1000: 0.8275938\n",
      "Epoch  300/1000: 0.8243083\n",
      "Epoch  400/1000: 0.8238681\n",
      "Epoch  500/1000: 0.8238091\n",
      "Epoch  600/1000: 0.8238012\n",
      "Epoch  700/1000: 0.8238001\n",
      "Epoch  800/1000: 0.8238000\n",
      "Epoch  900/1000: 0.8238000\n",
      "Epoch 1000/1000: 0.8238000\n",
      "Epoch  100/1000: 0.7507426\n",
      "Epoch  200/1000: 0.7222674\n",
      "Epoch  300/1000: 0.7184523\n",
      "Epoch  400/1000: 0.7179412\n",
      "Epoch  500/1000: 0.7178727\n",
      "Epoch  600/1000: 0.7178635\n",
      "Epoch  700/1000: 0.7178623\n",
      "Epoch  800/1000: 0.7178622\n",
      "Epoch  900/1000: 0.7178621\n",
      "Epoch 1000/1000: 0.7178621\n",
      "Epoch  100/1000: 0.7000633\n",
      "Epoch  200/1000: 0.6687396\n",
      "Epoch  300/1000: 0.6645377\n",
      "Epoch  400/1000: 0.6639733\n",
      "Epoch  500/1000: 0.6638973\n",
      "Epoch  600/1000: 0.6638871\n",
      "Epoch  700/1000: 0.6638857\n",
      "Epoch  800/1000: 0.6638856\n",
      "Epoch  900/1000: 0.6638855\n",
      "Epoch 1000/1000: 0.6638855\n",
      "Epoch  100/1000: 0.7441677\n",
      "Epoch  200/1000: 0.7126733\n",
      "Epoch  300/1000: 0.7084526\n",
      "Epoch  400/1000: 0.7078870\n",
      "Epoch  500/1000: 0.7078112\n",
      "Epoch  600/1000: 0.7078010\n",
      "Epoch  700/1000: 0.7077997\n",
      "Epoch  800/1000: 0.7077995\n",
      "Epoch  900/1000: 0.7077995\n",
      "Epoch 1000/1000: 0.7077995\n",
      "Epoch  100/1000: 0.7249112\n",
      "Epoch  200/1000: 0.6941372\n",
      "Epoch  300/1000: 0.6900186\n",
      "Epoch  400/1000: 0.6894671\n",
      "Epoch  500/1000: 0.6893932\n",
      "Epoch  600/1000: 0.6893833\n",
      "Epoch  700/1000: 0.6893820\n",
      "Epoch  800/1000: 0.6893818\n",
      "Epoch  900/1000: 0.6893818\n",
      "Epoch 1000/1000: 0.6893817\n",
      "Epoch  100/1000: 0.8507239\n",
      "Epoch  200/1000: 0.8261664\n",
      "Epoch  300/1000: 0.8228921\n",
      "Epoch  400/1000: 0.8224550\n",
      "Epoch  500/1000: 0.8223965\n",
      "Epoch  600/1000: 0.8223887\n",
      "Epoch  700/1000: 0.8223877\n",
      "Epoch  800/1000: 0.8223875\n",
      "Epoch  900/1000: 0.8223875\n",
      "Epoch 1000/1000: 0.8223875\n",
      "Epoch  100/1000: 0.7506591\n",
      "Epoch  200/1000: 0.7221997\n",
      "Epoch  300/1000: 0.7183878\n",
      "Epoch  400/1000: 0.7178769\n",
      "Epoch  500/1000: 0.7178083\n",
      "Epoch  600/1000: 0.7177991\n",
      "Epoch  700/1000: 0.7177979\n",
      "Epoch  800/1000: 0.7177977\n",
      "Epoch  900/1000: 0.7177977\n",
      "Epoch 1000/1000: 0.7177977\n",
      "Epoch  100/1000: 0.7178836\n",
      "Epoch  200/1000: 0.6759665\n",
      "Epoch  300/1000: 0.6434108\n",
      "Epoch  400/1000: 0.6159008\n",
      "Epoch  500/1000: 0.5926027\n",
      "Epoch  600/1000: 0.5728702\n",
      "Epoch  700/1000: 0.5561576\n",
      "Epoch  800/1000: 0.5420028\n",
      "Epoch  900/1000: 0.5300143\n",
      "Epoch 1000/1000: 0.5198605\n",
      "Epoch  100/1000: 0.7618867\n",
      "Epoch  200/1000: 0.7156230\n",
      "Epoch  300/1000: 0.6795321\n",
      "Epoch  400/1000: 0.6491593\n",
      "Epoch  500/1000: 0.6235421\n",
      "Epoch  600/1000: 0.6019338\n",
      "Epoch  700/1000: 0.5837070\n",
      "Epoch  800/1000: 0.5683325\n",
      "Epoch  900/1000: 0.5553639\n",
      "Epoch 1000/1000: 0.5444247\n",
      "Epoch  100/1000: 0.7421354\n",
      "Epoch  200/1000: 0.7004397\n",
      "Epoch  300/1000: 0.6685530\n",
      "Epoch  400/1000: 0.6419662\n",
      "Epoch  500/1000: 0.6197377\n",
      "Epoch  600/1000: 0.6011503\n",
      "Epoch  700/1000: 0.5856075\n",
      "Epoch  800/1000: 0.5726104\n",
      "Epoch  900/1000: 0.5617421\n",
      "Epoch 1000/1000: 0.5526540\n",
      "Epoch  100/1000: 0.8637973\n",
      "Epoch  200/1000: 0.8223994\n",
      "Epoch  300/1000: 0.7900187\n",
      "Epoch  400/1000: 0.7629709\n",
      "Epoch  500/1000: 0.7403260\n",
      "Epoch  600/1000: 0.7213647\n",
      "Epoch  700/1000: 0.7054873\n",
      "Epoch  800/1000: 0.6921923\n",
      "Epoch  900/1000: 0.6810596\n",
      "Epoch 1000/1000: 0.6717376\n",
      "Epoch  100/1000: 0.7664892\n",
      "Epoch  200/1000: 0.7243531\n",
      "Epoch  300/1000: 0.6916554\n",
      "Epoch  400/1000: 0.6641916\n",
      "Epoch  500/1000: 0.6410559\n",
      "Epoch  600/1000: 0.6215619\n",
      "Epoch  700/1000: 0.6051358\n",
      "Epoch  800/1000: 0.5912949\n",
      "Epoch  900/1000: 0.5796323\n",
      "Epoch 1000/1000: 0.5698051\n",
      "Epoch  100/1000: 0.7171054\n",
      "Epoch  200/1000: 0.6746206\n",
      "Epoch  300/1000: 0.6416193\n",
      "Epoch  400/1000: 0.6137341\n",
      "Epoch  500/1000: 0.5901187\n",
      "Epoch  600/1000: 0.5701175\n",
      "Epoch  700/1000: 0.5531769\n",
      "Epoch  800/1000: 0.5388280\n",
      "Epoch  900/1000: 0.5266739\n",
      "Epoch 1000/1000: 0.5163785\n",
      "Epoch  100/1000: 0.7618703\n",
      "Epoch  200/1000: 0.7152712\n",
      "Epoch  300/1000: 0.6787690\n",
      "Epoch  400/1000: 0.6479818\n",
      "Epoch  500/1000: 0.6219596\n",
      "Epoch  600/1000: 0.5999593\n",
      "Epoch  700/1000: 0.5813552\n",
      "Epoch  800/1000: 0.5656192\n",
      "Epoch  900/1000: 0.5523058\n",
      "Epoch 1000/1000: 0.5410389\n",
      "Epoch  100/1000: 0.7417287\n",
      "Epoch  200/1000: 0.6994799\n",
      "Epoch  300/1000: 0.6671114\n",
      "Epoch  400/1000: 0.6400971\n",
      "Epoch  500/1000: 0.6174872\n",
      "Epoch  600/1000: 0.5985591\n",
      "Epoch  700/1000: 0.5827112\n",
      "Epoch  800/1000: 0.5694405\n",
      "Epoch  900/1000: 0.5583265\n",
      "Epoch 1000/1000: 0.5490173\n",
      "Epoch  100/1000: 0.8635028\n",
      "Epoch  200/1000: 0.8211555\n",
      "Epoch  300/1000: 0.7878369\n",
      "Epoch  400/1000: 0.7599521\n",
      "Epoch  500/1000: 0.7365677\n",
      "Epoch  600/1000: 0.7169523\n",
      "Epoch  700/1000: 0.7004951\n",
      "Epoch  800/1000: 0.6866846\n",
      "Epoch  900/1000: 0.6750925\n",
      "Epoch 1000/1000: 0.6653600\n",
      "Epoch  100/1000: 0.7661552\n",
      "Epoch  200/1000: 0.7236215\n",
      "Epoch  300/1000: 0.6905612\n",
      "Epoch  400/1000: 0.6627636\n",
      "Epoch  500/1000: 0.6393201\n",
      "Epoch  600/1000: 0.6195423\n",
      "Epoch  700/1000: 0.6028548\n",
      "Epoch  800/1000: 0.5887731\n",
      "Epoch  900/1000: 0.5768885\n",
      "Epoch 1000/1000: 0.5668569\n",
      "Epoch  100/1000: 0.7136467\n",
      "Epoch  200/1000: 0.6431481\n",
      "Epoch  300/1000: 0.5945746\n",
      "Epoch  400/1000: 0.5608602\n",
      "Epoch  500/1000: 0.5374153\n",
      "Epoch  600/1000: 0.5210704\n",
      "Epoch  700/1000: 0.5096352\n",
      "Epoch  800/1000: 0.5015962\n",
      "Epoch  900/1000: 0.4959075\n",
      "Epoch 1000/1000: 0.4918463\n",
      "Epoch  100/1000: 0.7558121\n",
      "Epoch  200/1000: 0.6794654\n",
      "Epoch  300/1000: 0.6271377\n",
      "Epoch  400/1000: 0.5910090\n",
      "Epoch  500/1000: 0.5659883\n",
      "Epoch  600/1000: 0.5485891\n",
      "Epoch  700/1000: 0.5364220\n",
      "Epoch  800/1000: 0.5278497\n",
      "Epoch  900/1000: 0.5217494\n",
      "Epoch 1000/1000: 0.5173514\n",
      "Epoch  100/1000: 0.7371843\n",
      "Epoch  200/1000: 0.6674847\n",
      "Epoch  300/1000: 0.6208415\n",
      "Epoch  400/1000: 0.5893393\n",
      "Epoch  500/1000: 0.5680007\n",
      "Epoch  600/1000: 0.5534937\n",
      "Epoch  700/1000: 0.5435816\n",
      "Epoch  800/1000: 0.5367618\n",
      "Epoch  900/1000: 0.5320252\n",
      "Epoch 1000/1000: 0.5286934\n",
      "Epoch  100/1000: 0.8564371\n",
      "Epoch  200/1000: 0.7900008\n",
      "Epoch  300/1000: 0.7446999\n",
      "Epoch  400/1000: 0.7135649\n",
      "Epoch  500/1000: 0.6920795\n",
      "Epoch  600/1000: 0.6771743\n",
      "Epoch  700/1000: 0.6667602\n",
      "Epoch  800/1000: 0.6594142\n",
      "Epoch  900/1000: 0.6541666\n",
      "Epoch 1000/1000: 0.6503570\n",
      "Epoch  100/1000: 0.7607817\n",
      "Epoch  200/1000: 0.6918686\n",
      "Epoch  300/1000: 0.6449247\n",
      "Epoch  400/1000: 0.6126144\n",
      "Epoch  500/1000: 0.5902995\n",
      "Epoch  600/1000: 0.5748275\n",
      "Epoch  700/1000: 0.5640437\n",
      "Epoch  800/1000: 0.5564738\n",
      "Epoch  900/1000: 0.5511089\n",
      "Epoch 1000/1000: 0.5472583\n",
      "Epoch  100/1000: 0.7127447\n",
      "Epoch  200/1000: 0.6419782\n",
      "Epoch  300/1000: 0.5933113\n",
      "Epoch  400/1000: 0.5596078\n",
      "Epoch  500/1000: 0.5362328\n",
      "Epoch  600/1000: 0.5199884\n",
      "Epoch  700/1000: 0.5086672\n",
      "Epoch  800/1000: 0.5007456\n",
      "Epoch  900/1000: 0.4951718\n",
      "Epoch 1000/1000: 0.4912198\n",
      "Epoch  100/1000: 0.7554119\n",
      "Epoch  200/1000: 0.6785452\n",
      "Epoch  300/1000: 0.6258071\n",
      "Epoch  400/1000: 0.5893713\n",
      "Epoch  500/1000: 0.5641340\n",
      "Epoch  600/1000: 0.5465951\n",
      "Epoch  700/1000: 0.5343523\n",
      "Epoch  800/1000: 0.5257559\n",
      "Epoch  900/1000: 0.5196726\n",
      "Epoch 1000/1000: 0.5153235\n",
      "Epoch  100/1000: 0.7363194\n",
      "Epoch  200/1000: 0.6661040\n",
      "Epoch  300/1000: 0.6191372\n",
      "Epoch  400/1000: 0.5874443\n",
      "Epoch  500/1000: 0.5660093\n",
      "Epoch  600/1000: 0.5514723\n",
      "Epoch  700/1000: 0.5415765\n",
      "Epoch  800/1000: 0.5348051\n",
      "Epoch  900/1000: 0.5301383\n",
      "Epoch 1000/1000: 0.5268901\n",
      "Epoch  100/1000: 0.8551486\n",
      "Epoch  200/1000: 0.7876245\n",
      "Epoch  300/1000: 0.7416663\n",
      "Epoch  400/1000: 0.7101649\n",
      "Epoch  500/1000: 0.6885087\n",
      "Epoch  600/1000: 0.6735640\n",
      "Epoch  700/1000: 0.6631974\n",
      "Epoch  800/1000: 0.6559559\n",
      "Epoch  900/1000: 0.6508491\n",
      "Epoch 1000/1000: 0.6472021\n",
      "Epoch  100/1000: 0.7601008\n",
      "Epoch  200/1000: 0.6907456\n",
      "Epoch  300/1000: 0.6434930\n",
      "Epoch  400/1000: 0.6109756\n",
      "Epoch  500/1000: 0.5885317\n",
      "Epoch  600/1000: 0.5729902\n",
      "Epoch  700/1000: 0.5621819\n",
      "Epoch  800/1000: 0.5546212\n",
      "Epoch  900/1000: 0.5492902\n",
      "Epoch 1000/1000: 0.5454913\n",
      "Epoch  100/1000: 0.7002511\n",
      "Epoch  200/1000: 0.6171422\n",
      "Epoch  300/1000: 0.5699819\n",
      "Epoch  400/1000: 0.5428913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  500/1000: 0.5270354\n",
      "Epoch  600/1000: 0.5174788\n",
      "Epoch  700/1000: 0.5114636\n",
      "Epoch  800/1000: 0.5074482\n",
      "Epoch  900/1000: 0.5045706\n",
      "Epoch 1000/1000: 0.5023482\n",
      "Epoch  100/1000: 0.7410524\n",
      "Epoch  200/1000: 0.6520907\n",
      "Epoch  300/1000: 0.6017718\n",
      "Epoch  400/1000: 0.5728493\n",
      "Epoch  500/1000: 0.5558164\n",
      "Epoch  600/1000: 0.5454135\n",
      "Epoch  700/1000: 0.5387276\n",
      "Epoch  800/1000: 0.5341432\n",
      "Epoch  900/1000: 0.5307623\n",
      "Epoch 1000/1000: 0.5280845\n",
      "Epoch  100/1000: 0.7231777\n",
      "Epoch  200/1000: 0.6418001\n",
      "Epoch  300/1000: 0.5973797\n",
      "Epoch  400/1000: 0.5727378\n",
      "Epoch  500/1000: 0.5587408\n",
      "Epoch  600/1000: 0.5504934\n",
      "Epoch  700/1000: 0.5453671\n",
      "Epoch  800/1000: 0.5419485\n",
      "Epoch  900/1000: 0.5394763\n",
      "Epoch 1000/1000: 0.5375391\n",
      "Epoch  100/1000: 0.8433502\n",
      "Epoch  200/1000: 0.7671683\n",
      "Epoch  300/1000: 0.7238760\n",
      "Epoch  400/1000: 0.6988176\n",
      "Epoch  500/1000: 0.6839181\n",
      "Epoch  600/1000: 0.6747017\n",
      "Epoch  700/1000: 0.6686838\n",
      "Epoch  800/1000: 0.6644824\n",
      "Epoch  900/1000: 0.6613274\n",
      "Epoch 1000/1000: 0.6587880\n",
      "Epoch  100/1000: 0.7477667\n",
      "Epoch  200/1000: 0.6679415\n",
      "Epoch  300/1000: 0.6229718\n",
      "Epoch  400/1000: 0.5971695\n",
      "Epoch  500/1000: 0.5819939\n",
      "Epoch  600/1000: 0.5727342\n",
      "Epoch  700/1000: 0.5667840\n",
      "Epoch  800/1000: 0.5626988\n",
      "Epoch  900/1000: 0.5596768\n",
      "Epoch 1000/1000: 0.5572719\n",
      "Epoch  100/1000: 0.7000669\n",
      "Epoch  200/1000: 0.6687398\n",
      "Epoch  300/1000: 0.6645426\n",
      "Epoch  400/1000: 0.6639803\n",
      "Epoch  500/1000: 0.6639049\n",
      "Epoch  600/1000: 0.6638948\n",
      "Epoch  700/1000: 0.6638935\n",
      "Epoch  800/1000: 0.6638933\n",
      "Epoch  900/1000: 0.6638933\n",
      "Epoch 1000/1000: 0.6638933\n",
      "Epoch  100/1000: 0.7450012\n",
      "Epoch  200/1000: 0.7136262\n",
      "Epoch  300/1000: 0.7094226\n",
      "Epoch  400/1000: 0.7088594\n",
      "Epoch  500/1000: 0.7087840\n",
      "Epoch  600/1000: 0.7087739\n",
      "Epoch  700/1000: 0.7087725\n",
      "Epoch  800/1000: 0.7087723\n",
      "Epoch  900/1000: 0.7087723\n",
      "Epoch 1000/1000: 0.7087723\n",
      "Epoch  100/1000: 0.7252337\n",
      "Epoch  200/1000: 0.6944539\n",
      "Epoch  300/1000: 0.6903301\n",
      "Epoch  400/1000: 0.6897775\n",
      "Epoch  500/1000: 0.6897035\n",
      "Epoch  600/1000: 0.6896936\n",
      "Epoch  700/1000: 0.6896923\n",
      "Epoch  800/1000: 0.6896921\n",
      "Epoch  900/1000: 0.6896921\n",
      "Epoch 1000/1000: 0.6896921\n",
      "Epoch  100/1000: 0.8521224\n",
      "Epoch  200/1000: 0.8276006\n",
      "Epoch  300/1000: 0.8243152\n",
      "Epoch  400/1000: 0.8238750\n",
      "Epoch  500/1000: 0.8238160\n",
      "Epoch  600/1000: 0.8238081\n",
      "Epoch  700/1000: 0.8238070\n",
      "Epoch  800/1000: 0.8238069\n",
      "Epoch  900/1000: 0.8238069\n",
      "Epoch 1000/1000: 0.8238069\n",
      "Epoch  100/1000: 0.7507493\n",
      "Epoch  200/1000: 0.7222751\n",
      "Epoch  300/1000: 0.7184601\n",
      "Epoch  400/1000: 0.7179490\n",
      "Epoch  500/1000: 0.7178805\n",
      "Epoch  600/1000: 0.7178713\n",
      "Epoch  700/1000: 0.7178701\n",
      "Epoch  800/1000: 0.7178699\n",
      "Epoch  900/1000: 0.7178699\n",
      "Epoch 1000/1000: 0.7178699\n",
      "Epoch  100/1000: 0.7000697\n",
      "Epoch  200/1000: 0.6687468\n",
      "Epoch  300/1000: 0.6645450\n",
      "Epoch  400/1000: 0.6639806\n",
      "Epoch  500/1000: 0.6639047\n",
      "Epoch  600/1000: 0.6638945\n",
      "Epoch  700/1000: 0.6638931\n",
      "Epoch  800/1000: 0.6638930\n",
      "Epoch  900/1000: 0.6638929\n",
      "Epoch 1000/1000: 0.6638929\n",
      "Epoch  100/1000: 0.7441746\n",
      "Epoch  200/1000: 0.7126811\n",
      "Epoch  300/1000: 0.7084606\n",
      "Epoch  400/1000: 0.7078950\n",
      "Epoch  500/1000: 0.7078192\n",
      "Epoch  600/1000: 0.7078090\n",
      "Epoch  700/1000: 0.7078077\n",
      "Epoch  800/1000: 0.7078075\n",
      "Epoch  900/1000: 0.7078075\n",
      "Epoch 1000/1000: 0.7078075\n",
      "Epoch  100/1000: 0.7249182\n",
      "Epoch  200/1000: 0.6941451\n",
      "Epoch  300/1000: 0.6900266\n",
      "Epoch  400/1000: 0.6894751\n",
      "Epoch  500/1000: 0.6894013\n",
      "Epoch  600/1000: 0.6893913\n",
      "Epoch  700/1000: 0.6893900\n",
      "Epoch  800/1000: 0.6893898\n",
      "Epoch  900/1000: 0.6893898\n",
      "Epoch 1000/1000: 0.6893898\n",
      "Epoch  100/1000: 0.8507303\n",
      "Epoch  200/1000: 0.8261737\n",
      "Epoch  300/1000: 0.8228995\n",
      "Epoch  400/1000: 0.8224624\n",
      "Epoch  500/1000: 0.8224040\n",
      "Epoch  600/1000: 0.8223961\n",
      "Epoch  700/1000: 0.8223951\n",
      "Epoch  800/1000: 0.8223949\n",
      "Epoch  900/1000: 0.8223949\n",
      "Epoch 1000/1000: 0.8223949\n",
      "Epoch  100/1000: 0.7506660\n",
      "Epoch  200/1000: 0.7222075\n",
      "Epoch  300/1000: 0.7183956\n",
      "Epoch  400/1000: 0.7178847\n",
      "Epoch  500/1000: 0.7178162\n",
      "Epoch  600/1000: 0.7178070\n",
      "Epoch  700/1000: 0.7178058\n",
      "Epoch  800/1000: 0.7178056\n",
      "Epoch  900/1000: 0.7178056\n",
      "Epoch 1000/1000: 0.7178056\n",
      "Epoch  100/1000: 0.7178896\n",
      "Epoch  200/1000: 0.6759726\n",
      "Epoch  300/1000: 0.6434215\n",
      "Epoch  400/1000: 0.6159157\n",
      "Epoch  500/1000: 0.5926210\n",
      "Epoch  600/1000: 0.5728916\n",
      "Epoch  700/1000: 0.5561816\n",
      "Epoch  800/1000: 0.5420289\n",
      "Epoch  900/1000: 0.5300422\n",
      "Epoch 1000/1000: 0.5198900\n",
      "Epoch  100/1000: 0.7618930\n",
      "Epoch  200/1000: 0.7156301\n",
      "Epoch  300/1000: 0.6795442\n",
      "Epoch  400/1000: 0.6491757\n",
      "Epoch  500/1000: 0.6235621\n",
      "Epoch  600/1000: 0.6019570\n",
      "Epoch  700/1000: 0.5837328\n",
      "Epoch  800/1000: 0.5683604\n",
      "Epoch  900/1000: 0.5553936\n",
      "Epoch 1000/1000: 0.5444560\n",
      "Epoch  100/1000: 0.7421420\n",
      "Epoch  200/1000: 0.7004465\n",
      "Epoch  300/1000: 0.6685644\n",
      "Epoch  400/1000: 0.6419817\n",
      "Epoch  500/1000: 0.6197566\n",
      "Epoch  600/1000: 0.6011721\n",
      "Epoch  700/1000: 0.5856316\n",
      "Epoch  800/1000: 0.5726365\n",
      "Epoch  900/1000: 0.5617699\n",
      "Epoch 1000/1000: 0.5526832\n",
      "Epoch  100/1000: 0.8638032\n",
      "Epoch  200/1000: 0.8224071\n",
      "Epoch  300/1000: 0.7900311\n",
      "Epoch  400/1000: 0.7629872\n",
      "Epoch  500/1000: 0.7403457\n",
      "Epoch  600/1000: 0.7213871\n",
      "Epoch  700/1000: 0.7055120\n",
      "Epoch  800/1000: 0.6922190\n",
      "Epoch  900/1000: 0.6810879\n",
      "Epoch 1000/1000: 0.6717673\n",
      "Epoch  100/1000: 0.7664955\n",
      "Epoch  200/1000: 0.7243602\n",
      "Epoch  300/1000: 0.6916673\n",
      "Epoch  400/1000: 0.6642076\n",
      "Epoch  500/1000: 0.6410753\n",
      "Epoch  600/1000: 0.6215842\n",
      "Epoch  700/1000: 0.6051606\n",
      "Epoch  800/1000: 0.5913218\n",
      "Epoch  900/1000: 0.5796609\n",
      "Epoch 1000/1000: 0.5698351\n",
      "Epoch  100/1000: 0.7171120\n",
      "Epoch  200/1000: 0.6746280\n",
      "Epoch  300/1000: 0.6416318\n",
      "Epoch  400/1000: 0.6137513\n",
      "Epoch  500/1000: 0.5901398\n",
      "Epoch  600/1000: 0.5701420\n",
      "Epoch  700/1000: 0.5532042\n",
      "Epoch  800/1000: 0.5388578\n",
      "Epoch  900/1000: 0.5267058\n",
      "Epoch 1000/1000: 0.5164122\n",
      "Epoch  100/1000: 0.7618767\n",
      "Epoch  200/1000: 0.7152788\n",
      "Epoch  300/1000: 0.6787821\n",
      "Epoch  400/1000: 0.6479998\n",
      "Epoch  500/1000: 0.6219818\n",
      "Epoch  600/1000: 0.5999850\n",
      "Epoch  700/1000: 0.5813839\n",
      "Epoch  800/1000: 0.5656505\n",
      "Epoch  900/1000: 0.5523393\n",
      "Epoch 1000/1000: 0.5410744\n",
      "Epoch  100/1000: 0.7417357\n",
      "Epoch  200/1000: 0.6994878\n",
      "Epoch  300/1000: 0.6671245\n",
      "Epoch  400/1000: 0.6401147\n",
      "Epoch  500/1000: 0.6175087\n",
      "Epoch  600/1000: 0.5985839\n",
      "Epoch  700/1000: 0.5827387\n",
      "Epoch  800/1000: 0.5694704\n",
      "Epoch  900/1000: 0.5583583\n",
      "Epoch 1000/1000: 0.5490507\n",
      "Epoch  100/1000: 0.8635089\n",
      "Epoch  200/1000: 0.8211643\n",
      "Epoch  300/1000: 0.7878512\n",
      "Epoch  400/1000: 0.7599710\n",
      "Epoch  500/1000: 0.7365906\n",
      "Epoch  600/1000: 0.7169786\n",
      "Epoch  700/1000: 0.7005242\n",
      "Epoch  800/1000: 0.6867161\n",
      "Epoch  900/1000: 0.6751261\n",
      "Epoch 1000/1000: 0.6653953\n",
      "Epoch  100/1000: 0.7661619\n",
      "Epoch  200/1000: 0.7236295\n",
      "Epoch  300/1000: 0.6905746\n",
      "Epoch  400/1000: 0.6627815\n",
      "Epoch  500/1000: 0.6393418\n",
      "Epoch  600/1000: 0.6195673\n",
      "Epoch  700/1000: 0.6028827\n",
      "Epoch  800/1000: 0.5888033\n",
      "Epoch  900/1000: 0.5769207\n",
      "Epoch 1000/1000: 0.5668909\n",
      "Epoch  100/1000: 0.7136537\n",
      "Epoch  200/1000: 0.6431609\n",
      "Epoch  300/1000: 0.5945915\n",
      "Epoch  400/1000: 0.5608809\n",
      "Epoch  500/1000: 0.5374393\n",
      "Epoch  600/1000: 0.5210967\n",
      "Epoch  700/1000: 0.5096632\n",
      "Epoch  800/1000: 0.5016256\n",
      "Epoch  900/1000: 0.4959379\n",
      "Epoch 1000/1000: 0.4918775\n",
      "Epoch  100/1000: 0.7558192\n",
      "Epoch  200/1000: 0.6794784\n",
      "Epoch  300/1000: 0.6271551\n",
      "Epoch  400/1000: 0.5910309\n",
      "Epoch  500/1000: 0.5660135\n",
      "Epoch  600/1000: 0.5486167\n",
      "Epoch  700/1000: 0.5364516\n",
      "Epoch  800/1000: 0.5278807\n",
      "Epoch  900/1000: 0.5217816\n",
      "Epoch 1000/1000: 0.5173846\n",
      "Epoch  100/1000: 0.7371918\n",
      "Epoch  200/1000: 0.6674980\n",
      "Epoch  300/1000: 0.6208588\n",
      "Epoch  400/1000: 0.5893602\n",
      "Epoch  500/1000: 0.5680247\n",
      "Epoch  600/1000: 0.5535199\n",
      "Epoch  700/1000: 0.5436094\n",
      "Epoch  800/1000: 0.5367908\n",
      "Epoch  900/1000: 0.5320552\n",
      "Epoch 1000/1000: 0.5287242\n",
      "Epoch  100/1000: 0.8564444\n",
      "Epoch  200/1000: 0.7900137\n",
      "Epoch  300/1000: 0.7447178\n",
      "Epoch  400/1000: 0.7135871\n",
      "Epoch  500/1000: 0.6921047\n",
      "Epoch  600/1000: 0.6772019\n",
      "Epoch  700/1000: 0.6667896\n",
      "Epoch  800/1000: 0.6594449\n",
      "Epoch  900/1000: 0.6541985\n",
      "Epoch 1000/1000: 0.6503898\n",
      "Epoch  100/1000: 0.7607891\n",
      "Epoch  200/1000: 0.6918817\n",
      "Epoch  300/1000: 0.6449420\n",
      "Epoch  400/1000: 0.6126358\n",
      "Epoch  500/1000: 0.5903240\n",
      "Epoch  600/1000: 0.5748543\n",
      "Epoch  700/1000: 0.5640722\n",
      "Epoch  800/1000: 0.5565036\n",
      "Epoch  900/1000: 0.5511397\n",
      "Epoch 1000/1000: 0.5472900\n",
      "Epoch  100/1000: 0.7127520\n",
      "Epoch  200/1000: 0.6419916\n",
      "Epoch  300/1000: 0.5933289\n",
      "Epoch  400/1000: 0.5596291\n",
      "Epoch  500/1000: 0.5362572\n",
      "Epoch  600/1000: 0.5200151\n",
      "Epoch  700/1000: 0.5086955\n",
      "Epoch  800/1000: 0.5007751\n",
      "Epoch  900/1000: 0.4952022\n",
      "Epoch 1000/1000: 0.4912509\n",
      "Epoch  100/1000: 0.7554194\n",
      "Epoch  200/1000: 0.6785589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  300/1000: 0.6258253\n",
      "Epoch  400/1000: 0.5893941\n",
      "Epoch  500/1000: 0.5641601\n",
      "Epoch  600/1000: 0.5466237\n",
      "Epoch  700/1000: 0.5343826\n",
      "Epoch  800/1000: 0.5257876\n",
      "Epoch  900/1000: 0.5197053\n",
      "Epoch 1000/1000: 0.5153571\n",
      "Epoch  100/1000: 0.7363274\n",
      "Epoch  200/1000: 0.6661181\n",
      "Epoch  300/1000: 0.6191554\n",
      "Epoch  400/1000: 0.5874661\n",
      "Epoch  500/1000: 0.5660340\n",
      "Epoch  600/1000: 0.5514991\n",
      "Epoch  700/1000: 0.5416048\n",
      "Epoch  800/1000: 0.5348345\n",
      "Epoch  900/1000: 0.5301685\n",
      "Epoch 1000/1000: 0.5269209\n",
      "Epoch  100/1000: 0.8551565\n",
      "Epoch  200/1000: 0.7876384\n",
      "Epoch  300/1000: 0.7416854\n",
      "Epoch  400/1000: 0.7101883\n",
      "Epoch  500/1000: 0.6885351\n",
      "Epoch  600/1000: 0.6735926\n",
      "Epoch  700/1000: 0.6632276\n",
      "Epoch  800/1000: 0.6559873\n",
      "Epoch  900/1000: 0.6508814\n",
      "Epoch 1000/1000: 0.6472352\n",
      "Epoch  100/1000: 0.7601087\n",
      "Epoch  200/1000: 0.6907593\n",
      "Epoch  300/1000: 0.6435110\n",
      "Epoch  400/1000: 0.6109978\n",
      "Epoch  500/1000: 0.5885570\n",
      "Epoch  600/1000: 0.5730177\n",
      "Epoch  700/1000: 0.5622110\n",
      "Epoch  800/1000: 0.5546515\n",
      "Epoch  900/1000: 0.5493214\n",
      "Epoch 1000/1000: 0.5455232\n",
      "Epoch  100/1000: 0.7002603\n",
      "Epoch  200/1000: 0.6171590\n",
      "Epoch  300/1000: 0.5700028\n",
      "Epoch  400/1000: 0.5429144\n",
      "Epoch  500/1000: 0.5270596\n",
      "Epoch  600/1000: 0.5175034\n",
      "Epoch  700/1000: 0.5114882\n",
      "Epoch  800/1000: 0.5074728\n",
      "Epoch  900/1000: 0.5045958\n",
      "Epoch 1000/1000: 0.5023740\n",
      "Epoch  100/1000: 0.7410621\n",
      "Epoch  200/1000: 0.6521080\n",
      "Epoch  300/1000: 0.6017934\n",
      "Epoch  400/1000: 0.5728733\n",
      "Epoch  500/1000: 0.5558415\n",
      "Epoch  600/1000: 0.5454391\n",
      "Epoch  700/1000: 0.5387534\n",
      "Epoch  800/1000: 0.5341699\n",
      "Epoch  900/1000: 0.5307900\n",
      "Epoch 1000/1000: 0.5281130\n",
      "Epoch  100/1000: 0.7231875\n",
      "Epoch  200/1000: 0.6418175\n",
      "Epoch  300/1000: 0.5974010\n",
      "Epoch  400/1000: 0.5727612\n",
      "Epoch  500/1000: 0.5587652\n",
      "Epoch  600/1000: 0.5505182\n",
      "Epoch  700/1000: 0.5453919\n",
      "Epoch  800/1000: 0.5419733\n",
      "Epoch  900/1000: 0.5395014\n",
      "Epoch 1000/1000: 0.5375649\n",
      "Epoch  100/1000: 0.8433599\n",
      "Epoch  200/1000: 0.7671853\n",
      "Epoch  300/1000: 0.7238970\n",
      "Epoch  400/1000: 0.6988407\n",
      "Epoch  500/1000: 0.6839422\n",
      "Epoch  600/1000: 0.6747269\n",
      "Epoch  700/1000: 0.6687101\n",
      "Epoch  800/1000: 0.6645098\n",
      "Epoch  900/1000: 0.6613556\n",
      "Epoch 1000/1000: 0.6588171\n",
      "Epoch  100/1000: 0.7477764\n",
      "Epoch  200/1000: 0.6679585\n",
      "Epoch  300/1000: 0.6229928\n",
      "Epoch  400/1000: 0.5971925\n",
      "Epoch  500/1000: 0.5820179\n",
      "Epoch  600/1000: 0.5727587\n",
      "Epoch  700/1000: 0.5668088\n",
      "Epoch  800/1000: 0.5627245\n",
      "Epoch  900/1000: 0.5597033\n",
      "Epoch 1000/1000: 0.5572992\n",
      "Epoch  100/1000: 0.7006989\n",
      "Epoch  200/1000: 0.6694575\n",
      "Epoch  300/1000: 0.6652718\n",
      "Epoch  400/1000: 0.6647110\n",
      "Epoch  500/1000: 0.6646359\n",
      "Epoch  600/1000: 0.6646258\n",
      "Epoch  700/1000: 0.6646244\n",
      "Epoch  800/1000: 0.6646243\n",
      "Epoch  900/1000: 0.6646242\n",
      "Epoch 1000/1000: 0.6646242\n",
      "Epoch  100/1000: 0.7456457\n",
      "Epoch  200/1000: 0.7143582\n",
      "Epoch  300/1000: 0.7101663\n",
      "Epoch  400/1000: 0.7096047\n",
      "Epoch  500/1000: 0.7095294\n",
      "Epoch  600/1000: 0.7095193\n",
      "Epoch  700/1000: 0.7095180\n",
      "Epoch  800/1000: 0.7095178\n",
      "Epoch  900/1000: 0.7095178\n",
      "Epoch 1000/1000: 0.7095178\n",
      "Epoch  100/1000: 0.7259024\n",
      "Epoch  200/1000: 0.6952133\n",
      "Epoch  300/1000: 0.6911016\n",
      "Epoch  400/1000: 0.6905507\n",
      "Epoch  500/1000: 0.6904769\n",
      "Epoch  600/1000: 0.6904670\n",
      "Epoch  700/1000: 0.6904657\n",
      "Epoch  800/1000: 0.6904655\n",
      "Epoch  900/1000: 0.6904655\n",
      "Epoch 1000/1000: 0.6904654\n",
      "Epoch  100/1000: 0.8527137\n",
      "Epoch  200/1000: 0.8282719\n",
      "Epoch  300/1000: 0.8249972\n",
      "Epoch  400/1000: 0.8245585\n",
      "Epoch  500/1000: 0.8244997\n",
      "Epoch  600/1000: 0.8244918\n",
      "Epoch  700/1000: 0.8244908\n",
      "Epoch  800/1000: 0.8244906\n",
      "Epoch  900/1000: 0.8244906\n",
      "Epoch 1000/1000: 0.8244906\n",
      "Epoch  100/1000: 0.7514122\n",
      "Epoch  200/1000: 0.7230279\n",
      "Epoch  300/1000: 0.7192249\n",
      "Epoch  400/1000: 0.7187154\n",
      "Epoch  500/1000: 0.7186472\n",
      "Epoch  600/1000: 0.7186380\n",
      "Epoch  700/1000: 0.7186368\n",
      "Epoch  800/1000: 0.7186366\n",
      "Epoch  900/1000: 0.7186366\n",
      "Epoch 1000/1000: 0.7186366\n",
      "Epoch  100/1000: 0.7007042\n",
      "Epoch  200/1000: 0.6694642\n",
      "Epoch  300/1000: 0.6652731\n",
      "Epoch  400/1000: 0.6647111\n",
      "Epoch  500/1000: 0.6646359\n",
      "Epoch  600/1000: 0.6646258\n",
      "Epoch  700/1000: 0.6646244\n",
      "Epoch  800/1000: 0.6646243\n",
      "Epoch  900/1000: 0.6646242\n",
      "Epoch 1000/1000: 0.6646242\n",
      "Epoch  100/1000: 0.7448561\n",
      "Epoch  200/1000: 0.7134553\n",
      "Epoch  300/1000: 0.7092472\n",
      "Epoch  400/1000: 0.7086832\n",
      "Epoch  500/1000: 0.7086077\n",
      "Epoch  600/1000: 0.7085975\n",
      "Epoch  700/1000: 0.7085962\n",
      "Epoch  800/1000: 0.7085960\n",
      "Epoch  900/1000: 0.7085960\n",
      "Epoch 1000/1000: 0.7085960\n",
      "Epoch  100/1000: 0.7256095\n",
      "Epoch  200/1000: 0.6949282\n",
      "Epoch  300/1000: 0.6908218\n",
      "Epoch  400/1000: 0.6902719\n",
      "Epoch  500/1000: 0.6901982\n",
      "Epoch  600/1000: 0.6901883\n",
      "Epoch  700/1000: 0.6901870\n",
      "Epoch  800/1000: 0.6901868\n",
      "Epoch  900/1000: 0.6901868\n",
      "Epoch 1000/1000: 0.6901868\n",
      "Epoch  100/1000: 0.8513692\n",
      "Epoch  200/1000: 0.8268962\n",
      "Epoch  300/1000: 0.8236328\n",
      "Epoch  400/1000: 0.8231971\n",
      "Epoch  500/1000: 0.8231389\n",
      "Epoch  600/1000: 0.8231311\n",
      "Epoch  700/1000: 0.8231300\n",
      "Epoch  800/1000: 0.8231299\n",
      "Epoch  900/1000: 0.8231299\n",
      "Epoch 1000/1000: 0.8231299\n",
      "Epoch  100/1000: 0.7513405\n",
      "Epoch  200/1000: 0.7229714\n",
      "Epoch  300/1000: 0.7191712\n",
      "Epoch  400/1000: 0.7186618\n",
      "Epoch  500/1000: 0.7185935\n",
      "Epoch  600/1000: 0.7185843\n",
      "Epoch  700/1000: 0.7185831\n",
      "Epoch  800/1000: 0.7185829\n",
      "Epoch  900/1000: 0.7185829\n",
      "Epoch 1000/1000: 0.7185829\n",
      "Epoch  100/1000: 0.7184785\n",
      "Epoch  200/1000: 0.6765756\n",
      "Epoch  300/1000: 0.6444747\n",
      "Epoch  400/1000: 0.6173814\n",
      "Epoch  500/1000: 0.5944364\n",
      "Epoch  600/1000: 0.5750031\n",
      "Epoch  700/1000: 0.5585439\n",
      "Epoch  800/1000: 0.5446037\n",
      "Epoch  900/1000: 0.5327970\n",
      "Epoch 1000/1000: 0.5227971\n",
      "Epoch  100/1000: 0.7625211\n",
      "Epoch  200/1000: 0.7163349\n",
      "Epoch  300/1000: 0.6807446\n",
      "Epoch  400/1000: 0.6508015\n",
      "Epoch  500/1000: 0.6255469\n",
      "Epoch  600/1000: 0.6042445\n",
      "Epoch  700/1000: 0.5862757\n",
      "Epoch  800/1000: 0.5711188\n",
      "Epoch  900/1000: 0.5583337\n",
      "Epoch 1000/1000: 0.5475494\n",
      "Epoch  100/1000: 0.7427871\n",
      "Epoch  200/1000: 0.7011161\n",
      "Epoch  300/1000: 0.6696939\n",
      "Epoch  400/1000: 0.6435135\n",
      "Epoch  500/1000: 0.6216249\n",
      "Epoch  600/1000: 0.6033217\n",
      "Epoch  700/1000: 0.5880165\n",
      "Epoch  800/1000: 0.5752182\n",
      "Epoch  900/1000: 0.5645161\n",
      "Epoch 1000/1000: 0.5555669\n",
      "Epoch  100/1000: 0.8643835\n",
      "Epoch  200/1000: 0.8231676\n",
      "Epoch  300/1000: 0.7912538\n",
      "Epoch  400/1000: 0.7646002\n",
      "Epoch  500/1000: 0.7422854\n",
      "Epoch  600/1000: 0.7236004\n",
      "Epoch  700/1000: 0.7079545\n",
      "Epoch  800/1000: 0.6948533\n",
      "Epoch  900/1000: 0.6838829\n",
      "Epoch 1000/1000: 0.6746968\n",
      "Epoch  100/1000: 0.7671186\n",
      "Epoch  200/1000: 0.7250677\n",
      "Epoch  300/1000: 0.6928452\n",
      "Epoch  400/1000: 0.6657883\n",
      "Epoch  500/1000: 0.6429954\n",
      "Epoch  600/1000: 0.6237903\n",
      "Epoch  700/1000: 0.6076077\n",
      "Epoch  800/1000: 0.5939719\n",
      "Epoch  900/1000: 0.5824821\n",
      "Epoch 1000/1000: 0.5728005\n",
      "Epoch  100/1000: 0.7177673\n",
      "Epoch  200/1000: 0.6753595\n",
      "Epoch  300/1000: 0.6428616\n",
      "Epoch  400/1000: 0.6154392\n",
      "Epoch  500/1000: 0.5922173\n",
      "Epoch  600/1000: 0.5725508\n",
      "Epoch  700/1000: 0.5558949\n",
      "Epoch  800/1000: 0.5417884\n",
      "Epoch  900/1000: 0.5298406\n",
      "Epoch 1000/1000: 0.5197210\n",
      "Epoch  100/1000: 0.7625051\n",
      "Epoch  200/1000: 0.7160325\n",
      "Epoch  300/1000: 0.6800829\n",
      "Epoch  400/1000: 0.6497757\n",
      "Epoch  500/1000: 0.6241640\n",
      "Epoch  600/1000: 0.6025148\n",
      "Epoch  700/1000: 0.5842115\n",
      "Epoch  800/1000: 0.5687334\n",
      "Epoch  900/1000: 0.5556415\n",
      "Epoch 1000/1000: 0.5445650\n",
      "Epoch  100/1000: 0.7424285\n",
      "Epoch  200/1000: 0.7002641\n",
      "Epoch  300/1000: 0.6684102\n",
      "Epoch  400/1000: 0.6418504\n",
      "Epoch  500/1000: 0.6196240\n",
      "Epoch  600/1000: 0.6010194\n",
      "Epoch  700/1000: 0.5854447\n",
      "Epoch  800/1000: 0.5724049\n",
      "Epoch  900/1000: 0.5614862\n",
      "Epoch 1000/1000: 0.5523423\n",
      "Epoch  100/1000: 0.8641168\n",
      "Epoch  200/1000: 0.8220329\n",
      "Epoch  300/1000: 0.7892581\n",
      "Epoch  400/1000: 0.7618373\n",
      "Epoch  500/1000: 0.7388458\n",
      "Epoch  600/1000: 0.7195632\n",
      "Epoch  700/1000: 0.7033883\n",
      "Epoch  800/1000: 0.6898176\n",
      "Epoch  900/1000: 0.6784293\n",
      "Epoch 1000/1000: 0.6688703\n",
      "Epoch  100/1000: 0.7668277\n",
      "Epoch  200/1000: 0.7244294\n",
      "Epoch  300/1000: 0.6918910\n",
      "Epoch  400/1000: 0.6645434\n",
      "Epoch  500/1000: 0.6414824\n",
      "Epoch  600/1000: 0.6220301\n",
      "Epoch  700/1000: 0.6056197\n",
      "Epoch  800/1000: 0.5917740\n",
      "Epoch  900/1000: 0.5800908\n",
      "Epoch 1000/1000: 0.5702311\n",
      "Epoch  100/1000: 0.7143378\n",
      "Epoch  200/1000: 0.6444228\n",
      "Epoch  300/1000: 0.5962556\n",
      "Epoch  400/1000: 0.5629301\n",
      "Epoch  500/1000: 0.5398008\n",
      "Epoch  600/1000: 0.5236867\n",
      "Epoch  700/1000: 0.5124232\n",
      "Epoch  800/1000: 0.5045144\n",
      "Epoch  900/1000: 0.4989269\n",
      "Epoch 1000/1000: 0.4949461\n",
      "Epoch  100/1000: 0.7565226\n",
      "Epoch  200/1000: 0.6807686\n",
      "Epoch  300/1000: 0.6288711\n",
      "Epoch  400/1000: 0.5931914\n",
      "Epoch  500/1000: 0.5684993\n",
      "Epoch  600/1000: 0.5513448\n",
      "Epoch  700/1000: 0.5393640\n",
      "Epoch  800/1000: 0.5309368\n",
      "Epoch  900/1000: 0.5249527\n",
      "Epoch 1000/1000: 0.5206501\n",
      "Epoch  100/1000: 0.7379344\n",
      "Epoch  200/1000: 0.6688183\n",
      "Epoch  300/1000: 0.6225696\n",
      "Epoch  400/1000: 0.5914330\n",
      "Epoch  500/1000: 0.5703913\n",
      "Epoch  600/1000: 0.5560994\n",
      "Epoch  700/1000: 0.5463466\n",
      "Epoch  800/1000: 0.5396479\n",
      "Epoch  900/1000: 0.5350059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000: 0.5317504\n",
      "Epoch  100/1000: 0.8571612\n",
      "Epoch  200/1000: 0.7912915\n",
      "Epoch  300/1000: 0.7464919\n",
      "Epoch  400/1000: 0.7157764\n",
      "Epoch  500/1000: 0.6945971\n",
      "Epoch  600/1000: 0.6799202\n",
      "Epoch  700/1000: 0.6696800\n",
      "Epoch  800/1000: 0.6624699\n",
      "Epoch  900/1000: 0.6573317\n",
      "Epoch 1000/1000: 0.6536124\n",
      "Epoch  100/1000: 0.7615220\n",
      "Epoch  200/1000: 0.6931741\n",
      "Epoch  300/1000: 0.6466437\n",
      "Epoch  400/1000: 0.6147512\n",
      "Epoch  500/1000: 0.5927392\n",
      "Epoch  600/1000: 0.5774904\n",
      "Epoch  700/1000: 0.5668745\n",
      "Epoch  800/1000: 0.5594340\n",
      "Epoch  900/1000: 0.5541714\n",
      "Epoch 1000/1000: 0.5504040\n",
      "Epoch  100/1000: 0.7134776\n",
      "Epoch  200/1000: 0.6433112\n",
      "Epoch  300/1000: 0.5950557\n",
      "Epoch  400/1000: 0.5617363\n",
      "Epoch  500/1000: 0.5386696\n",
      "Epoch  600/1000: 0.5226460\n",
      "Epoch  700/1000: 0.5114850\n",
      "Epoch  800/1000: 0.5036815\n",
      "Epoch  900/1000: 0.4981965\n",
      "Epoch 1000/1000: 0.4943131\n",
      "Epoch  100/1000: 0.7561650\n",
      "Epoch  200/1000: 0.6799148\n",
      "Epoch  300/1000: 0.6276227\n",
      "Epoch  400/1000: 0.5916435\n",
      "Epoch  500/1000: 0.5667357\n",
      "Epoch  600/1000: 0.5494374\n",
      "Epoch  700/1000: 0.5373727\n",
      "Epoch  800/1000: 0.5289106\n",
      "Epoch  900/1000: 0.5229304\n",
      "Epoch 1000/1000: 0.5186624\n",
      "Epoch  100/1000: 0.7371102\n",
      "Epoch  200/1000: 0.6675011\n",
      "Epoch  300/1000: 0.6209398\n",
      "Epoch  400/1000: 0.5896129\n",
      "Epoch  500/1000: 0.5684709\n",
      "Epoch  600/1000: 0.5541409\n",
      "Epoch  700/1000: 0.5443936\n",
      "Epoch  800/1000: 0.5377306\n",
      "Epoch  900/1000: 0.5331447\n",
      "Epoch 1000/1000: 0.5299585\n",
      "Epoch  100/1000: 0.8559371\n",
      "Epoch  200/1000: 0.7890133\n",
      "Epoch  300/1000: 0.7435707\n",
      "Epoch  400/1000: 0.7124922\n",
      "Epoch  500/1000: 0.6911373\n",
      "Epoch  600/1000: 0.6764100\n",
      "Epoch  700/1000: 0.6662027\n",
      "Epoch  800/1000: 0.6590801\n",
      "Epoch  900/1000: 0.6540642\n",
      "Epoch 1000/1000: 0.6504884\n",
      "Epoch  100/1000: 0.7608799\n",
      "Epoch  200/1000: 0.6921115\n",
      "Epoch  300/1000: 0.6452838\n",
      "Epoch  400/1000: 0.6131883\n",
      "Epoch  500/1000: 0.5910456\n",
      "Epoch  600/1000: 0.5757216\n",
      "Epoch  700/1000: 0.5650726\n",
      "Epoch  800/1000: 0.5576305\n",
      "Epoch  900/1000: 0.5523897\n",
      "Epoch 1000/1000: 0.5486609\n",
      "Epoch  100/1000: 0.7011683\n",
      "Epoch  200/1000: 0.6188120\n",
      "Epoch  300/1000: 0.5720597\n",
      "Epoch  400/1000: 0.5451819\n",
      "Epoch  500/1000: 0.5294291\n",
      "Epoch  600/1000: 0.5199137\n",
      "Epoch  700/1000: 0.5139049\n",
      "Epoch  800/1000: 0.5098901\n",
      "Epoch  900/1000: 0.5070865\n",
      "Epoch 1000/1000: 0.5049341\n",
      "Epoch  100/1000: 0.7420151\n",
      "Epoch  200/1000: 0.6538188\n",
      "Epoch  300/1000: 0.6039229\n",
      "Epoch  400/1000: 0.5752273\n",
      "Epoch  500/1000: 0.5583100\n",
      "Epoch  600/1000: 0.5479590\n",
      "Epoch  700/1000: 0.5413008\n",
      "Epoch  800/1000: 0.5368169\n",
      "Epoch  900/1000: 0.5335273\n",
      "Epoch 1000/1000: 0.5309334\n",
      "Epoch  100/1000: 0.7241638\n",
      "Epoch  200/1000: 0.6435301\n",
      "Epoch  300/1000: 0.5995012\n",
      "Epoch  400/1000: 0.5750596\n",
      "Epoch  500/1000: 0.5611584\n",
      "Epoch  600/1000: 0.5529492\n",
      "Epoch  700/1000: 0.5478291\n",
      "Epoch  800/1000: 0.5443985\n",
      "Epoch  900/1000: 0.5419923\n",
      "Epoch 1000/1000: 0.5401227\n",
      "Epoch  100/1000: 0.8443259\n",
      "Epoch  200/1000: 0.7688654\n",
      "Epoch  300/1000: 0.7259646\n",
      "Epoch  400/1000: 0.7011131\n",
      "Epoch  500/1000: 0.6863157\n",
      "Epoch  600/1000: 0.6772155\n",
      "Epoch  700/1000: 0.6713151\n",
      "Epoch  800/1000: 0.6672139\n",
      "Epoch  900/1000: 0.6641472\n",
      "Epoch 1000/1000: 0.6616878\n",
      "Epoch  100/1000: 0.7487387\n",
      "Epoch  200/1000: 0.6696397\n",
      "Epoch  300/1000: 0.6250591\n",
      "Epoch  400/1000: 0.5994589\n",
      "Epoch  500/1000: 0.5843805\n",
      "Epoch  600/1000: 0.5751586\n",
      "Epoch  700/1000: 0.5692614\n",
      "Epoch  800/1000: 0.5652665\n",
      "Epoch  900/1000: 0.5623259\n",
      "Epoch 1000/1000: 0.5599959\n",
      "Epoch  100/1000: 0.7593456\n",
      "Epoch  200/1000: 0.7359933\n",
      "Epoch  300/1000: 0.7329009\n",
      "Epoch  400/1000: 0.7325266\n",
      "Epoch  500/1000: 0.7324613\n",
      "Epoch  600/1000: 0.7324053\n",
      "Epoch  700/1000: 0.7324016\n",
      "Epoch  800/1000: 0.7324462\n",
      "Epoch  900/1000: 0.7324716\n",
      "Epoch 1000/1000: 0.7324200\n",
      "Epoch  100/1000: 0.8044413\n",
      "Epoch  200/1000: 0.7810912\n",
      "Epoch  300/1000: 0.7780187\n",
      "Epoch  400/1000: 0.7775732\n",
      "Epoch  500/1000: 0.7774845\n",
      "Epoch  600/1000: 0.7775310\n",
      "Epoch  700/1000: 0.7775177\n",
      "Epoch  800/1000: 0.7774703\n",
      "Epoch  900/1000: 0.7775249\n",
      "Epoch 1000/1000: 0.7775262\n",
      "Epoch  100/1000: 0.7850829\n",
      "Epoch  200/1000: 0.7624047\n",
      "Epoch  300/1000: 0.7594050\n",
      "Epoch  400/1000: 0.7589699\n",
      "Epoch  500/1000: 0.7588903\n",
      "Epoch  600/1000: 0.7589401\n",
      "Epoch  700/1000: 0.7589198\n",
      "Epoch  800/1000: 0.7588950\n",
      "Epoch  900/1000: 0.7588961\n",
      "Epoch 1000/1000: 0.7589349\n",
      "Epoch  100/1000: 0.9047611\n",
      "Epoch  200/1000: 0.8872887\n",
      "Epoch  300/1000: 0.8849861\n",
      "Epoch  400/1000: 0.8847020\n",
      "Epoch  500/1000: 0.8846695\n",
      "Epoch  600/1000: 0.8845971\n",
      "Epoch  700/1000: 0.8846255\n",
      "Epoch  800/1000: 0.8846537\n",
      "Epoch  900/1000: 0.8846630\n",
      "Epoch 1000/1000: 0.8845962\n",
      "Epoch  100/1000: 0.8093786\n",
      "Epoch  200/1000: 0.7888049\n",
      "Epoch  300/1000: 0.7860655\n",
      "Epoch  400/1000: 0.7857104\n",
      "Epoch  500/1000: 0.7856309\n",
      "Epoch  600/1000: 0.7856370\n",
      "Epoch  700/1000: 0.7856493\n",
      "Epoch  800/1000: 0.7856388\n",
      "Epoch  900/1000: 0.7856321\n",
      "Epoch 1000/1000: 0.7856455\n",
      "Epoch  100/1000: 0.7594324\n",
      "Epoch  200/1000: 0.7360702\n",
      "Epoch  300/1000: 0.7329702\n",
      "Epoch  400/1000: 0.7325359\n",
      "Epoch  500/1000: 0.7325535\n",
      "Epoch  600/1000: 0.7324178\n",
      "Epoch  700/1000: 0.7324826\n",
      "Epoch  800/1000: 0.7324739\n",
      "Epoch  900/1000: 0.7325337\n",
      "Epoch 1000/1000: 0.7324707\n",
      "Epoch  100/1000: 0.8044460\n",
      "Epoch  200/1000: 0.7811593\n",
      "Epoch  300/1000: 0.7780488\n",
      "Epoch  400/1000: 0.7775861\n",
      "Epoch  500/1000: 0.7775591\n",
      "Epoch  600/1000: 0.7775708\n",
      "Epoch  700/1000: 0.7775231\n",
      "Epoch  800/1000: 0.7775435\n",
      "Epoch  900/1000: 0.7775753\n",
      "Epoch 1000/1000: 0.7775415\n",
      "Epoch  100/1000: 0.7851438\n",
      "Epoch  200/1000: 0.7624143\n",
      "Epoch  300/1000: 0.7594099\n",
      "Epoch  400/1000: 0.7590175\n",
      "Epoch  500/1000: 0.7589763\n",
      "Epoch  600/1000: 0.7589863\n",
      "Epoch  700/1000: 0.7589245\n",
      "Epoch  800/1000: 0.7589571\n",
      "Epoch  900/1000: 0.7589681\n",
      "Epoch 1000/1000: 0.7589655\n",
      "Epoch  100/1000: 0.9048097\n",
      "Epoch  200/1000: 0.8873067\n",
      "Epoch  300/1000: 0.8850450\n",
      "Epoch  400/1000: 0.8847178\n",
      "Epoch  500/1000: 0.8847087\n",
      "Epoch  600/1000: 0.8846576\n",
      "Epoch  700/1000: 0.8846651\n",
      "Epoch  800/1000: 0.8846606\n",
      "Epoch  900/1000: 0.8846885\n",
      "Epoch 1000/1000: 0.8846407\n",
      "Epoch  100/1000: 0.8094096\n",
      "Epoch  200/1000: 0.7888577\n",
      "Epoch  300/1000: 0.7860916\n",
      "Epoch  400/1000: 0.7857568\n",
      "Epoch  500/1000: 0.7857288\n",
      "Epoch  600/1000: 0.7856810\n",
      "Epoch  700/1000: 0.7856574\n",
      "Epoch  800/1000: 0.7856913\n",
      "Epoch  900/1000: 0.7857278\n",
      "Epoch 1000/1000: 0.7856926\n",
      "Epoch  100/1000: 0.7719173\n",
      "Epoch  200/1000: 0.7383402\n",
      "Epoch  300/1000: 0.7330700\n",
      "Epoch  400/1000: 0.7312027\n",
      "Epoch  500/1000: 0.7296152\n",
      "Epoch  600/1000: 0.7281953\n",
      "Epoch  700/1000: 0.7270871\n",
      "Epoch  800/1000: 0.7261876\n",
      "Epoch  900/1000: 0.7254256\n",
      "Epoch 1000/1000: 0.7246436\n",
      "Epoch  100/1000: 0.8160311\n",
      "Epoch  200/1000: 0.7828112\n",
      "Epoch  300/1000: 0.7774975\n",
      "Epoch  400/1000: 0.7745770\n",
      "Epoch  500/1000: 0.7721632\n",
      "Epoch  600/1000: 0.7701885\n",
      "Epoch  700/1000: 0.7684402\n",
      "Epoch  800/1000: 0.7669048\n",
      "Epoch  900/1000: 0.7657657\n",
      "Epoch 1000/1000: 0.7647721\n",
      "Epoch  100/1000: 0.7970443\n",
      "Epoch  200/1000: 0.7644300\n",
      "Epoch  300/1000: 0.7595017\n",
      "Epoch  400/1000: 0.7576926\n",
      "Epoch  500/1000: 0.7562770\n",
      "Epoch  600/1000: 0.7550696\n",
      "Epoch  700/1000: 0.7540430\n",
      "Epoch  800/1000: 0.7531721\n",
      "Epoch  900/1000: 0.7524885\n",
      "Epoch 1000/1000: 0.7519967\n",
      "Epoch  100/1000: 0.9111972\n",
      "Epoch  200/1000: 0.8879806\n",
      "Epoch  300/1000: 0.8843696\n",
      "Epoch  400/1000: 0.8821543\n",
      "Epoch  500/1000: 0.8803521\n",
      "Epoch  600/1000: 0.8787350\n",
      "Epoch  700/1000: 0.8775024\n",
      "Epoch  800/1000: 0.8764339\n",
      "Epoch  900/1000: 0.8755746\n",
      "Epoch 1000/1000: 0.8747186\n",
      "Epoch  100/1000: 0.8192668\n",
      "Epoch  200/1000: 0.7902090\n",
      "Epoch  300/1000: 0.7858885\n",
      "Epoch  400/1000: 0.7838271\n",
      "Epoch  500/1000: 0.7820411\n",
      "Epoch  600/1000: 0.7806456\n",
      "Epoch  700/1000: 0.7793622\n",
      "Epoch  800/1000: 0.7783921\n",
      "Epoch  900/1000: 0.7774909\n",
      "Epoch 1000/1000: 0.7767188\n",
      "Epoch  100/1000: 0.7719402\n",
      "Epoch  200/1000: 0.7383571\n",
      "Epoch  300/1000: 0.7330893\n",
      "Epoch  400/1000: 0.7312406\n",
      "Epoch  500/1000: 0.7296552\n",
      "Epoch  600/1000: 0.7282171\n",
      "Epoch  700/1000: 0.7271427\n",
      "Epoch  800/1000: 0.7261865\n",
      "Epoch  900/1000: 0.7254297\n",
      "Epoch 1000/1000: 0.7246707\n",
      "Epoch  100/1000: 0.8161098\n",
      "Epoch  200/1000: 0.7828559\n",
      "Epoch  300/1000: 0.7775315\n",
      "Epoch  400/1000: 0.7746690\n",
      "Epoch  500/1000: 0.7722448\n",
      "Epoch  600/1000: 0.7702101\n",
      "Epoch  700/1000: 0.7684397\n",
      "Epoch  800/1000: 0.7669894\n",
      "Epoch  900/1000: 0.7658776\n",
      "Epoch 1000/1000: 0.7648350\n",
      "Epoch  100/1000: 0.7971206\n",
      "Epoch  200/1000: 0.7645035\n",
      "Epoch  300/1000: 0.7596132\n",
      "Epoch  400/1000: 0.7578159\n",
      "Epoch  500/1000: 0.7563100\n",
      "Epoch  600/1000: 0.7551614\n",
      "Epoch  700/1000: 0.7540768\n",
      "Epoch  800/1000: 0.7532339\n",
      "Epoch  900/1000: 0.7526257\n",
      "Epoch 1000/1000: 0.7519671\n",
      "Epoch  100/1000: 0.9112949\n",
      "Epoch  200/1000: 0.8879800\n",
      "Epoch  300/1000: 0.8844225\n",
      "Epoch  400/1000: 0.8822119\n",
      "Epoch  500/1000: 0.8803659\n",
      "Epoch  600/1000: 0.8787754\n",
      "Epoch  700/1000: 0.8775987\n",
      "Epoch  800/1000: 0.8764700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  900/1000: 0.8755937\n",
      "Epoch 1000/1000: 0.8747154\n",
      "Epoch  100/1000: 0.8193372\n",
      "Epoch  200/1000: 0.7902295\n",
      "Epoch  300/1000: 0.7858985\n",
      "Epoch  400/1000: 0.7839261\n",
      "Epoch  500/1000: 0.7820739\n",
      "Epoch  600/1000: 0.7806912\n",
      "Epoch  700/1000: 0.7794751\n",
      "Epoch  800/1000: 0.7784053\n",
      "Epoch  900/1000: 0.7775370\n",
      "Epoch 1000/1000: 0.7767949\n",
      "Epoch  100/1000: 0.7720325\n",
      "Epoch  200/1000: 0.7368694\n",
      "Epoch  300/1000: 0.7244113\n",
      "Epoch  400/1000: 0.7162415\n",
      "Epoch  500/1000: 0.7104552\n",
      "Epoch  600/1000: 0.7064361\n",
      "Epoch  700/1000: 0.7034987\n",
      "Epoch  800/1000: 0.7016265\n",
      "Epoch  900/1000: 0.7003960\n",
      "Epoch 1000/1000: 0.6993426\n",
      "Epoch  100/1000: 0.8161172\n",
      "Epoch  200/1000: 0.7797781\n",
      "Epoch  300/1000: 0.7653707\n",
      "Epoch  400/1000: 0.7556370\n",
      "Epoch  500/1000: 0.7489550\n",
      "Epoch  600/1000: 0.7442633\n",
      "Epoch  700/1000: 0.7410339\n",
      "Epoch  800/1000: 0.7387520\n",
      "Epoch  900/1000: 0.7372834\n",
      "Epoch 1000/1000: 0.7362298\n",
      "Epoch  100/1000: 0.7971571\n",
      "Epoch  200/1000: 0.7629634\n",
      "Epoch  300/1000: 0.7508429\n",
      "Epoch  400/1000: 0.7429943\n",
      "Epoch  500/1000: 0.7377527\n",
      "Epoch  600/1000: 0.7341567\n",
      "Epoch  700/1000: 0.7317275\n",
      "Epoch  800/1000: 0.7301191\n",
      "Epoch  900/1000: 0.7288525\n",
      "Epoch 1000/1000: 0.7281651\n",
      "Epoch  100/1000: 0.9112889\n",
      "Epoch  200/1000: 0.8853639\n",
      "Epoch  300/1000: 0.8746740\n",
      "Epoch  400/1000: 0.8673300\n",
      "Epoch  500/1000: 0.8622864\n",
      "Epoch  600/1000: 0.8587931\n",
      "Epoch  700/1000: 0.8564189\n",
      "Epoch  800/1000: 0.8547454\n",
      "Epoch  900/1000: 0.8537299\n",
      "Epoch 1000/1000: 0.8527568\n",
      "Epoch  100/1000: 0.8193598\n",
      "Epoch  200/1000: 0.7882059\n",
      "Epoch  300/1000: 0.7765037\n",
      "Epoch  400/1000: 0.7687508\n",
      "Epoch  500/1000: 0.7632641\n",
      "Epoch  600/1000: 0.7594144\n",
      "Epoch  700/1000: 0.7568644\n",
      "Epoch  800/1000: 0.7550567\n",
      "Epoch  900/1000: 0.7538032\n",
      "Epoch 1000/1000: 0.7529509\n",
      "Epoch  100/1000: 0.7719801\n",
      "Epoch  200/1000: 0.7368977\n",
      "Epoch  300/1000: 0.7244360\n",
      "Epoch  400/1000: 0.7163255\n",
      "Epoch  500/1000: 0.7104952\n",
      "Epoch  600/1000: 0.7064447\n",
      "Epoch  700/1000: 0.7036369\n",
      "Epoch  800/1000: 0.7017127\n",
      "Epoch  900/1000: 0.7003697\n",
      "Epoch 1000/1000: 0.6993292\n",
      "Epoch  100/1000: 0.8162121\n",
      "Epoch  200/1000: 0.7798764\n",
      "Epoch  300/1000: 0.7654093\n",
      "Epoch  400/1000: 0.7557063\n",
      "Epoch  500/1000: 0.7490681\n",
      "Epoch  600/1000: 0.7442895\n",
      "Epoch  700/1000: 0.7409561\n",
      "Epoch  800/1000: 0.7388330\n",
      "Epoch  900/1000: 0.7373998\n",
      "Epoch 1000/1000: 0.7362827\n",
      "Epoch  100/1000: 0.7972313\n",
      "Epoch  200/1000: 0.7630118\n",
      "Epoch  300/1000: 0.7508606\n",
      "Epoch  400/1000: 0.7432165\n",
      "Epoch  500/1000: 0.7378302\n",
      "Epoch  600/1000: 0.7342790\n",
      "Epoch  700/1000: 0.7318097\n",
      "Epoch  800/1000: 0.7301528\n",
      "Epoch  900/1000: 0.7288943\n",
      "Epoch 1000/1000: 0.7282623\n",
      "Epoch  100/1000: 0.9112947\n",
      "Epoch  200/1000: 0.8854421\n",
      "Epoch  300/1000: 0.8746939\n",
      "Epoch  400/1000: 0.8674695\n",
      "Epoch  500/1000: 0.8623684\n",
      "Epoch  600/1000: 0.8587879\n",
      "Epoch  700/1000: 0.8565215\n",
      "Epoch  800/1000: 0.8548001\n",
      "Epoch  900/1000: 0.8537542\n",
      "Epoch 1000/1000: 0.8528230\n",
      "Epoch  100/1000: 0.8193779\n",
      "Epoch  200/1000: 0.7883831\n",
      "Epoch  300/1000: 0.7766470\n",
      "Epoch  400/1000: 0.7686517\n",
      "Epoch  500/1000: 0.7632749\n",
      "Epoch  600/1000: 0.7595754\n",
      "Epoch  700/1000: 0.7568818\n",
      "Epoch  800/1000: 0.7550668\n",
      "Epoch  900/1000: 0.7539097\n",
      "Epoch 1000/1000: 0.7529785\n",
      "Epoch  100/1000: 0.7716983\n",
      "Epoch  200/1000: 0.7321595\n",
      "Epoch  300/1000: 0.7155010\n",
      "Epoch  400/1000: 0.7062844\n",
      "Epoch  500/1000: 0.7011258\n",
      "Epoch  600/1000: 0.6980716\n",
      "Epoch  700/1000: 0.6964081\n",
      "Epoch  800/1000: 0.6954678\n",
      "Epoch  900/1000: 0.6949485\n",
      "Epoch 1000/1000: 0.6946181\n",
      "Epoch  100/1000: 0.8155910\n",
      "Epoch  200/1000: 0.7736300\n",
      "Epoch  300/1000: 0.7550262\n",
      "Epoch  400/1000: 0.7447027\n",
      "Epoch  500/1000: 0.7389892\n",
      "Epoch  600/1000: 0.7358262\n",
      "Epoch  700/1000: 0.7340058\n",
      "Epoch  800/1000: 0.7329890\n",
      "Epoch  900/1000: 0.7325381\n",
      "Epoch 1000/1000: 0.7323096\n",
      "Epoch  100/1000: 0.7967869\n",
      "Epoch  200/1000: 0.7581252\n",
      "Epoch  300/1000: 0.7422969\n",
      "Epoch  400/1000: 0.7337336\n",
      "Epoch  500/1000: 0.7290088\n",
      "Epoch  600/1000: 0.7267522\n",
      "Epoch  700/1000: 0.7252700\n",
      "Epoch  800/1000: 0.7245509\n",
      "Epoch  900/1000: 0.7240540\n",
      "Epoch 1000/1000: 0.7239062\n",
      "Epoch  100/1000: 0.9110983\n",
      "Epoch  200/1000: 0.8810675\n",
      "Epoch  300/1000: 0.8671833\n",
      "Epoch  400/1000: 0.8595568\n",
      "Epoch  500/1000: 0.8553034\n",
      "Epoch  600/1000: 0.8528730\n",
      "Epoch  700/1000: 0.8515703\n",
      "Epoch  800/1000: 0.8509291\n",
      "Epoch  900/1000: 0.8505101\n",
      "Epoch 1000/1000: 0.8502244\n",
      "Epoch  100/1000: 0.8191313\n",
      "Epoch  200/1000: 0.7837961\n",
      "Epoch  300/1000: 0.7683926\n",
      "Epoch  400/1000: 0.7598692\n",
      "Epoch  500/1000: 0.7552166\n",
      "Epoch  600/1000: 0.7526254\n",
      "Epoch  700/1000: 0.7511526\n",
      "Epoch  800/1000: 0.7502803\n",
      "Epoch  900/1000: 0.7497546\n",
      "Epoch 1000/1000: 0.7495366\n",
      "Epoch  100/1000: 0.0593355\n",
      "Epoch  200/1000: 0.0439553\n",
      "Epoch  300/1000: 0.0418835\n",
      "Epoch  400/1000: 0.0416025\n",
      "Epoch  500/1000: 0.0415640\n",
      "Epoch  600/1000: 0.0415587\n",
      "Epoch  700/1000: 0.0415579\n",
      "Epoch  800/1000: 0.0415578\n",
      "Epoch  900/1000: 0.0415578\n",
      "Epoch 1000/1000: 0.0415578\n",
      "Epoch  100/1000: 0.0599068\n",
      "Epoch  200/1000: 0.0449230\n",
      "Epoch  300/1000: 0.0429097\n",
      "Epoch  400/1000: 0.0426388\n",
      "Epoch  500/1000: 0.0426023\n",
      "Epoch  600/1000: 0.0425974\n",
      "Epoch  700/1000: 0.0425967\n",
      "Epoch  800/1000: 0.0425966\n",
      "Epoch  900/1000: 0.0425966\n",
      "Epoch 1000/1000: 0.0425966\n",
      "Epoch  100/1000: 0.0584719\n",
      "Epoch  200/1000: 0.0430204\n",
      "Epoch  300/1000: 0.0409530\n",
      "Epoch  400/1000: 0.0406763\n",
      "Epoch  500/1000: 0.0406392\n",
      "Epoch  600/1000: 0.0406343\n",
      "Epoch  700/1000: 0.0406336\n",
      "Epoch  800/1000: 0.0406335\n",
      "Epoch  900/1000: 0.0406335\n",
      "Epoch 1000/1000: 0.0406335\n",
      "Epoch  100/1000: 0.0584064\n",
      "Epoch  200/1000: 0.0444273\n",
      "Epoch  300/1000: 0.0425576\n",
      "Epoch  400/1000: 0.0423074\n",
      "Epoch  500/1000: 0.0422739\n",
      "Epoch  600/1000: 0.0422694\n",
      "Epoch  700/1000: 0.0422688\n",
      "Epoch  800/1000: 0.0422688\n",
      "Epoch  900/1000: 0.0422687\n",
      "Epoch 1000/1000: 0.0422687\n",
      "Epoch  100/1000: 0.0615001\n",
      "Epoch  200/1000: 0.0443145\n",
      "Epoch  300/1000: 0.0420133\n",
      "Epoch  400/1000: 0.0417050\n",
      "Epoch  500/1000: 0.0416637\n",
      "Epoch  600/1000: 0.0416582\n",
      "Epoch  700/1000: 0.0416574\n",
      "Epoch  800/1000: 0.0416573\n",
      "Epoch  900/1000: 0.0416573\n",
      "Epoch 1000/1000: 0.0416573\n",
      "Epoch  100/1000: 0.0574484\n",
      "Epoch  200/1000: 0.0421288\n",
      "Epoch  300/1000: 0.0399557\n",
      "Epoch  400/1000: 0.0395723\n",
      "Epoch  500/1000: 0.0394444\n",
      "Epoch  600/1000: 0.0393610\n",
      "Epoch  700/1000: 0.0392909\n",
      "Epoch  800/1000: 0.0392281\n",
      "Epoch  900/1000: 0.0391706\n",
      "Epoch 1000/1000: 0.0391175\n",
      "Epoch  100/1000: 0.0589997\n",
      "Epoch  200/1000: 0.0440015\n",
      "Epoch  300/1000: 0.0418996\n",
      "Epoch  400/1000: 0.0415434\n",
      "Epoch  500/1000: 0.0414308\n",
      "Epoch  600/1000: 0.0413568\n",
      "Epoch  700/1000: 0.0412922\n",
      "Epoch  800/1000: 0.0412322\n",
      "Epoch  900/1000: 0.0411754\n",
      "Epoch 1000/1000: 0.0411213\n",
      "Epoch  100/1000: 0.0568112\n",
      "Epoch  200/1000: 0.0408050\n",
      "Epoch  300/1000: 0.0383465\n",
      "Epoch  400/1000: 0.0377721\n",
      "Epoch  500/1000: 0.0374871\n",
      "Epoch  600/1000: 0.0372643\n",
      "Epoch  700/1000: 0.0370670\n",
      "Epoch  800/1000: 0.0368868\n",
      "Epoch  900/1000: 0.0367206\n",
      "Epoch 1000/1000: 0.0365668\n",
      "Epoch  100/1000: 0.0579382\n",
      "Epoch  200/1000: 0.0438599\n",
      "Epoch  300/1000: 0.0418527\n",
      "Epoch  400/1000: 0.0414918\n",
      "Epoch  500/1000: 0.0413680\n",
      "Epoch  600/1000: 0.0412864\n",
      "Epoch  700/1000: 0.0412172\n",
      "Epoch  800/1000: 0.0411545\n",
      "Epoch  900/1000: 0.0410965\n",
      "Epoch 1000/1000: 0.0410422\n",
      "Epoch  100/1000: 0.0606383\n",
      "Epoch  200/1000: 0.0430725\n",
      "Epoch  300/1000: 0.0403814\n",
      "Epoch  400/1000: 0.0397767\n",
      "Epoch  500/1000: 0.0395048\n",
      "Epoch  600/1000: 0.0393107\n",
      "Epoch  700/1000: 0.0391490\n",
      "Epoch  800/1000: 0.0390075\n",
      "Epoch  900/1000: 0.0388809\n",
      "Epoch 1000/1000: 0.0387659\n",
      "Epoch  100/1000: 0.0564910\n",
      "Epoch  200/1000: 0.0406453\n",
      "Epoch  300/1000: 0.0380704\n",
      "Epoch  400/1000: 0.0373783\n",
      "Epoch  500/1000: 0.0370043\n",
      "Epoch  600/1000: 0.0367175\n",
      "Epoch  700/1000: 0.0364744\n",
      "Epoch  800/1000: 0.0362614\n",
      "Epoch  900/1000: 0.0360717\n",
      "Epoch 1000/1000: 0.0359009\n",
      "Epoch  100/1000: 0.0577336\n",
      "Epoch  200/1000: 0.0422492\n",
      "Epoch  300/1000: 0.0397494\n",
      "Epoch  400/1000: 0.0390701\n",
      "Epoch  500/1000: 0.0386882\n",
      "Epoch  600/1000: 0.0383836\n",
      "Epoch  700/1000: 0.0381170\n",
      "Epoch  800/1000: 0.0378769\n",
      "Epoch  900/1000: 0.0376576\n",
      "Epoch 1000/1000: 0.0374556\n",
      "Epoch  100/1000: 0.0551912\n",
      "Epoch  200/1000: 0.0384771\n",
      "Epoch  300/1000: 0.0355224\n",
      "Epoch  400/1000: 0.0346083\n",
      "Epoch  500/1000: 0.0340986\n",
      "Epoch  600/1000: 0.0337310\n",
      "Epoch  700/1000: 0.0334426\n",
      "Epoch  800/1000: 0.0332070\n",
      "Epoch  900/1000: 0.0330089\n",
      "Epoch 1000/1000: 0.0328383\n",
      "Epoch  100/1000: 0.0567254\n",
      "Epoch  200/1000: 0.0422375\n",
      "Epoch  300/1000: 0.0399157\n",
      "Epoch  400/1000: 0.0392779\n",
      "Epoch  500/1000: 0.0389054\n",
      "Epoch  600/1000: 0.0385994\n",
      "Epoch  700/1000: 0.0383275\n",
      "Epoch  800/1000: 0.0380812\n",
      "Epoch  900/1000: 0.0378562\n",
      "Epoch 1000/1000: 0.0376494\n",
      "Epoch  100/1000: 0.0587953\n",
      "Epoch  200/1000: 0.0406219\n",
      "Epoch  300/1000: 0.0376716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  400/1000: 0.0369473\n",
      "Epoch  500/1000: 0.0366269\n",
      "Epoch  600/1000: 0.0364206\n",
      "Epoch  700/1000: 0.0362642\n",
      "Epoch  800/1000: 0.0361347\n",
      "Epoch  900/1000: 0.0360213\n",
      "Epoch 1000/1000: 0.0359180\n",
      "Epoch  100/1000: 0.0594999\n",
      "Epoch  200/1000: 0.0441426\n",
      "Epoch  300/1000: 0.0420741\n",
      "Epoch  400/1000: 0.0417936\n",
      "Epoch  500/1000: 0.0417552\n",
      "Epoch  600/1000: 0.0417499\n",
      "Epoch  700/1000: 0.0417491\n",
      "Epoch  800/1000: 0.0417490\n",
      "Epoch  900/1000: 0.0417490\n",
      "Epoch 1000/1000: 0.0417490\n",
      "Epoch  100/1000: 0.0600636\n",
      "Epoch  200/1000: 0.0451019\n",
      "Epoch  300/1000: 0.0430917\n",
      "Epoch  400/1000: 0.0428213\n",
      "Epoch  500/1000: 0.0427848\n",
      "Epoch  600/1000: 0.0427799\n",
      "Epoch  700/1000: 0.0427793\n",
      "Epoch  800/1000: 0.0427792\n",
      "Epoch  900/1000: 0.0427791\n",
      "Epoch 1000/1000: 0.0427791\n",
      "Epoch  100/1000: 0.0586253\n",
      "Epoch  200/1000: 0.0431939\n",
      "Epoch  300/1000: 0.0411291\n",
      "Epoch  400/1000: 0.0408527\n",
      "Epoch  500/1000: 0.0408157\n",
      "Epoch  600/1000: 0.0408107\n",
      "Epoch  700/1000: 0.0408101\n",
      "Epoch  800/1000: 0.0408100\n",
      "Epoch  900/1000: 0.0408100\n",
      "Epoch 1000/1000: 0.0408100\n",
      "Epoch  100/1000: 0.0585581\n",
      "Epoch  200/1000: 0.0445991\n",
      "Epoch  300/1000: 0.0427320\n",
      "Epoch  400/1000: 0.0424822\n",
      "Epoch  500/1000: 0.0424488\n",
      "Epoch  600/1000: 0.0424443\n",
      "Epoch  700/1000: 0.0424437\n",
      "Epoch  800/1000: 0.0424436\n",
      "Epoch  900/1000: 0.0424436\n",
      "Epoch 1000/1000: 0.0424436\n",
      "Epoch  100/1000: 0.0616746\n",
      "Epoch  200/1000: 0.0445124\n",
      "Epoch  300/1000: 0.0422143\n",
      "Epoch  400/1000: 0.0419064\n",
      "Epoch  500/1000: 0.0418652\n",
      "Epoch  600/1000: 0.0418597\n",
      "Epoch  700/1000: 0.0418589\n",
      "Epoch  800/1000: 0.0418588\n",
      "Epoch  900/1000: 0.0418588\n",
      "Epoch 1000/1000: 0.0418588\n",
      "Epoch  100/1000: 0.0576461\n",
      "Epoch  200/1000: 0.0423741\n",
      "Epoch  300/1000: 0.0402214\n",
      "Epoch  400/1000: 0.0398533\n",
      "Epoch  500/1000: 0.0397396\n",
      "Epoch  600/1000: 0.0396685\n",
      "Epoch  700/1000: 0.0396092\n",
      "Epoch  800/1000: 0.0395595\n",
      "Epoch  900/1000: 0.0395147\n",
      "Epoch 1000/1000: 0.0394741\n",
      "Epoch  100/1000: 0.0591840\n",
      "Epoch  200/1000: 0.0442263\n",
      "Epoch  300/1000: 0.0421397\n",
      "Epoch  400/1000: 0.0417940\n",
      "Epoch  500/1000: 0.0416917\n",
      "Epoch  600/1000: 0.0416273\n",
      "Epoch  700/1000: 0.0415724\n",
      "Epoch  800/1000: 0.0415235\n",
      "Epoch  900/1000: 0.0414776\n",
      "Epoch 1000/1000: 0.0414338\n",
      "Epoch  100/1000: 0.0570279\n",
      "Epoch  200/1000: 0.0410807\n",
      "Epoch  300/1000: 0.0386543\n",
      "Epoch  400/1000: 0.0381055\n",
      "Epoch  500/1000: 0.0378449\n",
      "Epoch  600/1000: 0.0376466\n",
      "Epoch  700/1000: 0.0374744\n",
      "Epoch  800/1000: 0.0373175\n",
      "Epoch  900/1000: 0.0371748\n",
      "Epoch 1000/1000: 0.0370444\n",
      "Epoch  100/1000: 0.0581106\n",
      "Epoch  200/1000: 0.0440785\n",
      "Epoch  300/1000: 0.0420943\n",
      "Epoch  400/1000: 0.0417528\n",
      "Epoch  500/1000: 0.0416462\n",
      "Epoch  600/1000: 0.0415813\n",
      "Epoch  700/1000: 0.0415280\n",
      "Epoch  800/1000: 0.0414805\n",
      "Epoch  900/1000: 0.0414368\n",
      "Epoch 1000/1000: 0.0413962\n",
      "Epoch  100/1000: 0.0608598\n",
      "Epoch  200/1000: 0.0433588\n",
      "Epoch  300/1000: 0.0407064\n",
      "Epoch  400/1000: 0.0401307\n",
      "Epoch  500/1000: 0.0398833\n",
      "Epoch  600/1000: 0.0397116\n",
      "Epoch  700/1000: 0.0395715\n",
      "Epoch  800/1000: 0.0394509\n",
      "Epoch  900/1000: 0.0393433\n",
      "Epoch 1000/1000: 0.0392460\n",
      "Epoch  100/1000: 0.0567899\n",
      "Epoch  200/1000: 0.0410577\n",
      "Epoch  300/1000: 0.0385589\n",
      "Epoch  400/1000: 0.0379280\n",
      "Epoch  500/1000: 0.0376055\n",
      "Epoch  600/1000: 0.0373648\n",
      "Epoch  700/1000: 0.0371658\n",
      "Epoch  800/1000: 0.0369937\n",
      "Epoch  900/1000: 0.0368422\n",
      "Epoch 1000/1000: 0.0367073\n",
      "Epoch  100/1000: 0.0580158\n",
      "Epoch  200/1000: 0.0426409\n",
      "Epoch  300/1000: 0.0402255\n",
      "Epoch  400/1000: 0.0396196\n",
      "Epoch  500/1000: 0.0393008\n",
      "Epoch  600/1000: 0.0390517\n",
      "Epoch  700/1000: 0.0388376\n",
      "Epoch  800/1000: 0.0386458\n",
      "Epoch  900/1000: 0.0384716\n",
      "Epoch 1000/1000: 0.0383120\n",
      "Epoch  100/1000: 0.0555322\n",
      "Epoch  200/1000: 0.0389520\n",
      "Epoch  300/1000: 0.0360878\n",
      "Epoch  400/1000: 0.0352402\n",
      "Epoch  500/1000: 0.0347824\n",
      "Epoch  600/1000: 0.0344607\n",
      "Epoch  700/1000: 0.0342133\n",
      "Epoch  800/1000: 0.0340130\n",
      "Epoch  900/1000: 0.0338470\n",
      "Epoch 1000/1000: 0.0337053\n",
      "Epoch  100/1000: 0.0569991\n",
      "Epoch  200/1000: 0.0426156\n",
      "Epoch  300/1000: 0.0403659\n",
      "Epoch  400/1000: 0.0397903\n",
      "Epoch  500/1000: 0.0394760\n",
      "Epoch  600/1000: 0.0392289\n",
      "Epoch  700/1000: 0.0390116\n",
      "Epoch  800/1000: 0.0388165\n",
      "Epoch  900/1000: 0.0386396\n",
      "Epoch 1000/1000: 0.0384779\n",
      "Epoch  100/1000: 0.0591424\n",
      "Epoch  200/1000: 0.0410901\n",
      "Epoch  300/1000: 0.0382098\n",
      "Epoch  400/1000: 0.0375330\n",
      "Epoch  500/1000: 0.0372475\n",
      "Epoch  600/1000: 0.0370688\n",
      "Epoch  700/1000: 0.0369356\n",
      "Epoch  800/1000: 0.0368266\n",
      "Epoch  900/1000: 0.0367324\n",
      "Epoch 1000/1000: 0.0366480\n",
      "Epoch  100/1000: 0.0645192\n",
      "Epoch  200/1000: 0.0498641\n",
      "Epoch  300/1000: 0.0478972\n",
      "Epoch  400/1000: 0.0476319\n",
      "Epoch  500/1000: 0.0475960\n",
      "Epoch  600/1000: 0.0475910\n",
      "Epoch  700/1000: 0.0475904\n",
      "Epoch  800/1000: 0.0475903\n",
      "Epoch  900/1000: 0.0475903\n",
      "Epoch 1000/1000: 0.0475902\n",
      "Epoch  100/1000: 0.0648478\n",
      "Epoch  200/1000: 0.0505565\n",
      "Epoch  300/1000: 0.0486404\n",
      "Epoch  400/1000: 0.0483833\n",
      "Epoch  500/1000: 0.0483488\n",
      "Epoch  600/1000: 0.0483441\n",
      "Epoch  700/1000: 0.0483435\n",
      "Epoch  800/1000: 0.0483434\n",
      "Epoch  900/1000: 0.0483434\n",
      "Epoch 1000/1000: 0.0483434\n",
      "Epoch  100/1000: 0.0633478\n",
      "Epoch  200/1000: 0.0485414\n",
      "Epoch  300/1000: 0.0465595\n",
      "Epoch  400/1000: 0.0462933\n",
      "Epoch  500/1000: 0.0462578\n",
      "Epoch  600/1000: 0.0462532\n",
      "Epoch  700/1000: 0.0462528\n",
      "Epoch  800/1000: 0.0462530\n",
      "Epoch  900/1000: 0.0462529\n",
      "Epoch 1000/1000: 0.0462525\n",
      "Epoch  100/1000: 0.0631957\n",
      "Epoch  200/1000: 0.0498513\n",
      "Epoch  300/1000: 0.0480651\n",
      "Epoch  400/1000: 0.0478259\n",
      "Epoch  500/1000: 0.0477939\n",
      "Epoch  600/1000: 0.0477896\n",
      "Epoch  700/1000: 0.0477890\n",
      "Epoch  800/1000: 0.0477890\n",
      "Epoch  900/1000: 0.0477890\n",
      "Epoch 1000/1000: 0.0477890\n",
      "Epoch  100/1000: 0.0670315\n",
      "Epoch  200/1000: 0.0505869\n",
      "Epoch  300/1000: 0.0483842\n",
      "Epoch  400/1000: 0.0480891\n",
      "Epoch  500/1000: 0.0480496\n",
      "Epoch  600/1000: 0.0480443\n",
      "Epoch  700/1000: 0.0480435\n",
      "Epoch  800/1000: 0.0480435\n",
      "Epoch  900/1000: 0.0480434\n",
      "Epoch 1000/1000: 0.0480434\n",
      "Epoch  100/1000: 0.0631612\n",
      "Epoch  200/1000: 0.0486700\n",
      "Epoch  300/1000: 0.0467076\n",
      "Epoch  400/1000: 0.0464223\n",
      "Epoch  500/1000: 0.0463679\n",
      "Epoch  600/1000: 0.0463493\n",
      "Epoch  700/1000: 0.0463403\n",
      "Epoch  800/1000: 0.0463379\n",
      "Epoch  900/1000: 0.0463371\n",
      "Epoch 1000/1000: 0.0463364\n",
      "Epoch  100/1000: 0.0643338\n",
      "Epoch  200/1000: 0.0501313\n",
      "Epoch  300/1000: 0.0482209\n",
      "Epoch  400/1000: 0.0479581\n",
      "Epoch  500/1000: 0.0479172\n",
      "Epoch  600/1000: 0.0479077\n",
      "Epoch  700/1000: 0.0479071\n",
      "Epoch  800/1000: 0.0479034\n",
      "Epoch  900/1000: 0.0479022\n",
      "Epoch 1000/1000: 0.0478997\n",
      "Epoch  100/1000: 0.0627260\n",
      "Epoch  200/1000: 0.0477885\n",
      "Epoch  300/1000: 0.0457388\n",
      "Epoch  400/1000: 0.0454578\n",
      "Epoch  500/1000: 0.0454094\n",
      "Epoch  600/1000: 0.0454000\n",
      "Epoch  700/1000: 0.0453964\n",
      "Epoch  800/1000: 0.0453930\n",
      "Epoch  900/1000: 0.0453900\n",
      "Epoch 1000/1000: 0.0453903\n",
      "Epoch  100/1000: 0.0628996\n",
      "Epoch  200/1000: 0.0495922\n",
      "Epoch  300/1000: 0.0478004\n",
      "Epoch  400/1000: 0.0475580\n",
      "Epoch  500/1000: 0.0475218\n",
      "Epoch  600/1000: 0.0475119\n",
      "Epoch  700/1000: 0.0475108\n",
      "Epoch  800/1000: 0.0475085\n",
      "Epoch  900/1000: 0.0475089\n",
      "Epoch 1000/1000: 0.0475068\n",
      "Epoch  100/1000: 0.0668031\n",
      "Epoch  200/1000: 0.0504244\n",
      "Epoch  300/1000: 0.0481902\n",
      "Epoch  400/1000: 0.0478648\n",
      "Epoch  500/1000: 0.0478102\n",
      "Epoch  600/1000: 0.0477922\n",
      "Epoch  700/1000: 0.0477841\n",
      "Epoch  800/1000: 0.0477761\n",
      "Epoch  900/1000: 0.0477705\n",
      "Epoch 1000/1000: 0.0477668\n",
      "Epoch  100/1000: 0.0631388\n",
      "Epoch  200/1000: 0.0486321\n",
      "Epoch  300/1000: 0.0466677\n",
      "Epoch  400/1000: 0.0463775\n",
      "Epoch  500/1000: 0.0463301\n",
      "Epoch  600/1000: 0.0463138\n",
      "Epoch  700/1000: 0.0463022\n",
      "Epoch  800/1000: 0.0462928\n",
      "Epoch  900/1000: 0.0462856\n",
      "Epoch 1000/1000: 0.0462846\n",
      "Epoch  100/1000: 0.0643369\n",
      "Epoch  200/1000: 0.0500986\n",
      "Epoch  300/1000: 0.0481661\n",
      "Epoch  400/1000: 0.0478973\n",
      "Epoch  500/1000: 0.0478572\n",
      "Epoch  600/1000: 0.0478392\n",
      "Epoch  700/1000: 0.0478304\n",
      "Epoch  800/1000: 0.0478202\n",
      "Epoch  900/1000: 0.0478109\n",
      "Epoch 1000/1000: 0.0478115\n",
      "Epoch  100/1000: 0.0624906\n",
      "Epoch  200/1000: 0.0476513\n",
      "Epoch  300/1000: 0.0456473\n",
      "Epoch  400/1000: 0.0453686\n",
      "Epoch  500/1000: 0.0453276\n",
      "Epoch  600/1000: 0.0453173\n",
      "Epoch  700/1000: 0.0453102\n",
      "Epoch  800/1000: 0.0453086\n",
      "Epoch  900/1000: 0.0453051\n",
      "Epoch 1000/1000: 0.0453002\n",
      "Epoch  100/1000: 0.0628037\n",
      "Epoch  200/1000: 0.0494962\n",
      "Epoch  300/1000: 0.0477099\n",
      "Epoch  400/1000: 0.0474674\n",
      "Epoch  500/1000: 0.0474347\n",
      "Epoch  600/1000: 0.0474302\n",
      "Epoch  700/1000: 0.0474237\n",
      "Epoch  800/1000: 0.0474276\n",
      "Epoch  900/1000: 0.0474299\n",
      "Epoch 1000/1000: 0.0474227\n",
      "Epoch  100/1000: 0.0666385\n",
      "Epoch  200/1000: 0.0501573\n",
      "Epoch  300/1000: 0.0478861\n",
      "Epoch  400/1000: 0.0475371\n",
      "Epoch  500/1000: 0.0474655\n",
      "Epoch  600/1000: 0.0474321\n",
      "Epoch  700/1000: 0.0474096\n",
      "Epoch  800/1000: 0.0473910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  900/1000: 0.0473760\n",
      "Epoch 1000/1000: 0.0473684\n",
      "[test_error_values] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def grid_search_for_hyperparameters(data, labels, num_of_folds, lambdas, degrees):\n",
    "    \"\"\" A function which stores the validation error for all combinations of hyperparameters.\n",
    "        \n",
    "    Args:\n",
    "        data (np.array): Shape (N, D).\n",
    "        labels (np.array): Shape (N, ).\n",
    "        num_of_folds (int): Number of folds.\n",
    "        lambdas (np.array): Array of different regularization coefficients to try.\n",
    "        degrees (np.array): Array of different degrees coefficients to try for \n",
    "        feature expansion.\n",
    "\n",
    "    Returns:\n",
    "        (np.array): Cross-validation error values of all different \n",
    "        combinations of hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    k_fold_ind = fold_indices(data.shape[0], num_of_folds)\n",
    "    error_values = np.zeros([lambdas.shape[0], degrees.shape[0]])\n",
    "\n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "    \n",
    "    # Write two nested loops that loop over the lambdas and the degrees. \n",
    "    # Run the cross validation function and store the error in `error_values`.\n",
    "    for i, lmbda in enumerate(lambdas):\n",
    "        for j, degree in enumerate(degrees):\n",
    "            error_values[i, j] = run_cross_validation(k_fold_ind, num_of_folds, data, labels, lmbda, degree)\n",
    "    \n",
    "    #######################################\n",
    "        \n",
    "    return error_values\n",
    "\n",
    "\n",
    "lambdas = np.concatenate((np.array([0]), np.logspace(-5, -1, 3)))\n",
    "degrees = np.arange(1, 8)\n",
    "num_of_folds = 5\n",
    " \n",
    "error_values = grid_search_for_hyperparameters(X_train, y_train, num_of_folds, lambdas, degrees)\n",
    "tests.test_error_values(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the validation error values for all the different hyperparameter combinations, we have to find the combination which results in the lowest error value. Please fill in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda 0.0\n",
      "Best degree 6\n",
      "[test_hyperparameters] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def find_best_hyperparameters(error_values, lambdas, degrees):\n",
    "    \"\"\" A function which finds the hyperparameters that give the lowest error\n",
    "        \n",
    "    Args:\n",
    "        error_values (np.array) Cross-validation error values of all different \n",
    "        combinations of hyperparameters.\n",
    "        lambdas (np.array): Array of different regularization coefficients to try.\n",
    "        degrees (np.array): Array of different degrees coefficients to try for \n",
    "        feature expansion.\n",
    "\n",
    "    Returns:\n",
    "        (float), (int): Lambda and degree combination that result in lowest error\n",
    "    \"\"\"    \n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "\n",
    "    # Extract the lambda and degree resulting in the lowest error.\n",
    "    \n",
    "    # Using min+where\n",
    "    #min_value = np.min(error_values)\n",
    "    #best_ind = np.where(error_values == min_value)\n",
    "    #i = best_ind[0][0]\n",
    "    #j = best_ind[1][0]\n",
    "    \n",
    "    # Using argmin\n",
    "    best_ind = np.argmin(error_values)\n",
    "    i = best_ind // error_values.shape[1]\n",
    "    j = best_ind % error_values.shape[1]\n",
    "    \n",
    "    degree_best = degrees[j]\n",
    "    lambda_best = lambdas[i]\n",
    "    \n",
    "    #######################################\n",
    "    return lambda_best, degree_best\n",
    "\n",
    "lambda_best, degree_best = find_best_hyperparameters(error_values, lambdas, degrees)\n",
    "print('Best lambda', lambda_best)\n",
    "print('Best degree', degree_best)    \n",
    "    \n",
    "tests.test_hyperparameters(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helpers.plot_grid_search_results(error_values, lambdas, degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the best lambda and degree value, train your model again on **all the training data** we have. Use the degree you found for the feature expansion and lambda for regularization. Then, find the predictions on the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000: 0.7650584\n",
      "Epoch  200/1000: 0.6941424\n",
      "Epoch  300/1000: 0.6458173\n",
      "Epoch  400/1000: 0.6126536\n",
      "Epoch  500/1000: 0.5898446\n",
      "Epoch  600/1000: 0.5741121\n",
      "Epoch  700/1000: 0.5632177\n",
      "Epoch  800/1000: 0.5556325\n",
      "Epoch  900/1000: 0.5503121\n",
      "Epoch 1000/1000: 0.5465427\n",
      "Epoch  100/500: 0.0597463\n",
      "Epoch  200/500: 0.0444667\n",
      "Epoch  300/500: 0.0423403\n",
      "Epoch  400/500: 0.0419966\n",
      "Epoch  500/500: 0.0419038\n",
      "[test_train_and_predict_final_model] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "def train_and_predict_final_model(data_train, labels_train, data_test, lmbda, degree, epochs=1000, lr=1e-2):\n",
    "    \"\"\" Train a LASSO regression model using gradient descent. \n",
    "    Use weights to predict labels of test data.\n",
    "        \n",
    "    Args:\n",
    "        data_train (np.array): Training data.\n",
    "        labels_train (np.array): Labels of training data.\n",
    "        data_test (np.array): Test data\n",
    "        lmbda (float): The regularization coefficient. \n",
    "        degree (int): The degree of the polynomial feature expansion.\n",
    "        feature expansion.\n",
    "        epochs (int): # Epochs.\n",
    "        lr (float): Learning rate.\n",
    "\n",
    "    Returns:\n",
    "        (np.array): Model weights.\n",
    "        (np.array): Predicted labels.\n",
    "    \"\"\"   \n",
    "    #######################################\n",
    "    # Please fill in the required code here\n",
    "\n",
    "    # Expand and normalize your training data.\n",
    "    data_train = expand(data_train, degree)\n",
    "    \n",
    "    expand_no_bias = data_train[:, 1:]\n",
    "    mu, std = find_stats(expand_no_bias)\n",
    "    expand_no_bias = normalize(expand_no_bias, mu, std)\n",
    "    \n",
    "    data_train[:, 1:] = expand_no_bias\n",
    "    \n",
    "\n",
    "    # Train with Gradient Descent\n",
    "    w_end = training_with_gd(data_train, labels_train, epochs, lr, lmbda)\n",
    "    \n",
    "    #Expand and normalize your test data\n",
    "    #(Think about what statistics to use to normalize)\n",
    "    data_test = expand(data_test, degree)\n",
    "    \n",
    "    expand_no_bias = data_test[:, 1:]\n",
    "    expand_no_bias = normalize(expand_no_bias, mu, std)\n",
    "    \n",
    "    data_test[:, 1:] = expand_no_bias\n",
    "\n",
    "    #Predict using w_end\n",
    "    labels_predicted = data_test @ w_end\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    return w_end, labels_predicted\n",
    "\n",
    "w_end, labels_predicted = train_and_predict_final_model(X_train, y_train, X_test, lambda_best, degree_best)\n",
    "tests.test_train_and_predict_final_model(locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical T/F questions \n",
    "\n",
    "* Every correct answer is +1 point and every incorrect answer is -1 point.\n",
    "* Fill in the list in the cell below with your answers, then run the cell. It will generate a .txt file called TF_answers. Check to make sure this is created.\n",
    "* While filling the list, mark the true statements as T, the false statements as F and the question you skip with X. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### QUESTIONS\n",
       "1. LASSO regression is NOT robust toward outliers compared to linear regression.\n",
       "2. High degree feature expansion leads to overfitting.\n",
       "3. A model that has overfit to the training data is robust towards outliers.\n",
       "4. In the LASSO regression formula, if we set lambda to a very large value, our optimization would result in weights being 0."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions = helpers.show_theory_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Your answers:\n",
       "1. LASSO regression is NOT robust toward outliers compared to linear regression.: **False**\n",
       "2. High degree feature expansion leads to overfitting.: **True**\n",
       "3. A model that has overfit to the training data is robust towards outliers.: **False**\n",
       "4. In the LASSO regression formula, if we set lambda to a very large value, our optimization would result in weights being 0.: **True**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_theory_answers] - No problems detected. Your code is correct! ðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "theory_answers = ['X'] * len(questions)\n",
    "\n",
    "theory_answers[0] = 'F'\n",
    "theory_answers[1] = 'T'\n",
    "theory_answers[2] = 'F'\n",
    "theory_answers[3] = 'T'\n",
    "\n",
    "helpers.print_answers(theory_answers)\n",
    "\n",
    "tests.test_theory_answers(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### You have reached the end of the tests.\n",
       "\n",
       "### [**Click here to go to moodle to upload your submission**](https://moodle.epfl.ch/mod/assign/view.php?id=1023343).\n",
       "\n",
       "Please submit the following files ONLY:\n",
       "- `graded_exercise_2.ipynb`\n",
       "- `answers_274999.npz` (automatically generated)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "helpers.show_submission_instructions(locals());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
